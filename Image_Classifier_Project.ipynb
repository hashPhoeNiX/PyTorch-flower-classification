{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classifier Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hashPhoeNiX/PyTorch-flower-classification/blob/master/Image_Classifier_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "z1iZPUK5gKlj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Developing an AI application\n",
        "\n",
        "Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications. \n",
        "\n",
        "In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories, you can see a few examples below. \n",
        "\n",
        "<img src='assets/Flowers.png' width=500px>\n",
        "\n",
        "The project is broken down into multiple steps:\n",
        "\n",
        "* Load and preprocess the image dataset\n",
        "* Train the image classifier on your dataset\n",
        "* Use the trained classifier to predict image content\n",
        "\n",
        "We'll lead you through each part which you'll implement in Python.\n",
        "\n",
        "When you've completed this project, you'll have an application that can be trained on any set of labeled images. Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new.\n",
        "\n",
        "First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here."
      ]
    },
    {
      "metadata": {
        "id": "wjL2BUaegSTb",
        "colab_type": "code",
        "outputId": "ad39f2ae-ae62-4b11-ab02-5360fd75b812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!wget \"https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-11 14:51:57--  https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.98.253\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.98.253|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 311442766 (297M) [application/zip]\n",
            "Saving to: ‘flower_data.zip’\n",
            "\n",
            "flower_data.zip     100%[===================>] 297.01M  92.6MB/s    in 3.4s    \n",
            "\n",
            "2019-01-11 14:52:01 (87.6 MB/s) - ‘flower_data.zip’ saved [311442766/311442766]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GndIcQfNiu-W",
        "colab_type": "code",
        "outputId": "b2f10668-1d47-4ab1-efe6-bf0795ac1173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -L \"https://drive.google.com/uc?export=download&id=1yUXRP47N1-vgzAwvoY-5CuFOIIkebAnq\" > test.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0     64      0 --:--:--  0:00:05 --:--:--   102\n",
            "100 33.6M    0 33.6M    0     0  4611k      0 --:--:--  0:00:07 --:--:--  124M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yrwnNR57g4UU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !unzip test.zip -d flower_data\n",
        "\n",
        "!unzip flower_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zZokNTSUhAuA",
        "colab_type": "code",
        "outputId": "0e62b675-a3d4-4b2f-cd01-8967b9e129d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5c5b8000 @  0x7f7effede2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x_U5EjH0ig4h",
        "colab_type": "code",
        "outputId": "8525c9a0-58df-4433-9c40-b2a9f7c58ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall -y Pillow\n",
        "# install the new one\n",
        "!pip install Pillow==5.3.0\n",
        "# import the new one\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Pillow-5.4.1:\n",
            "  Successfully uninstalled Pillow-5.4.1\n",
            "Collecting Pillow==5.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 17.8MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "Successfully installed Pillow-5.3.0\n",
            "4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3u7B4ZY7gKln",
        "colab_type": "code",
        "outputId": "b6eefa20-1c7d-46a8-b62c-0828f1c13656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Imports here\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "%matplotlib InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: unrecognized arguments: = 'retina'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "J_1iWnkNgKl4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the data\n",
        "\n",
        "Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). You can [download the data here](https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip). The dataset is split into two parts, training and validation. For the training, you'll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. If you use a pre-trained network, you'll also need to make sure the input data is resized to 224x224 pixels as required by the networks.\n",
        "\n",
        "The validation set is used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n",
        "\n",
        "The pre-trained networks available from `torchvision` were trained on the ImageNet dataset where each color channel was normalized separately. For both sets you'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1."
      ]
    },
    {
      "metadata": {
        "id": "VoxlrW_fgKl7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = './flower_data'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z4ynEanTgKmB",
        "colab_type": "code",
        "outputId": "f681f2aa-e3c0-49c7-d43b-206d47fd74ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "cell_type": "code",
      "source": [
        "# TODO: Define your transforms for the training and validation sets\n",
        "data_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                      transforms.RandomResizedCrop(224),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "valid_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                       transforms.CenterCrop(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "image_datasets = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
        "valid_datasets = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
        "test_datasets = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "dataloaders = torch.utils.data.DataLoader(image_datasets, batch_size=32, shuffle=True)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_datasets, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_datasets, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9ed716986d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# TODO: Load the datasets with ImageFolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mvalid_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtest_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader)\u001b[0m\n\u001b[1;32m    176\u001b[0m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS,\n\u001b[1;32m    177\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                                           target_transform=target_transform)\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './flower_data/train'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "dMdjJjDTgKmF",
        "colab_type": "code",
        "outputId": "bf50162e-13e5-40a8-e20f-be57c205e00f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Number of Train set: \", len(image_datasets))\n",
        "print(\"Number of Valid set: \", len(valid_datasets))\n",
        "print(\"Number of Valid set: \", len(test_datasets))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Train set:  6552\n",
            "Number of Valid set:  818\n",
            "Number of Valid set:  819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fn50YO86gKmJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Label mapping\n",
        "\n",
        "You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/2/library/json.html). This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
      ]
    },
    {
      "metadata": {
        "id": "cJe1lQrndsVX",
        "colab_type": "code",
        "outputId": "5440551b-004c-4777-820f-13b84b66e4ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -L \"https://drive.google.com/uc?export=download&id=1yDOBhEpQKXwN0HDRAgQGJawesUk_e0fu/view?usp=sharing\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<HTML>\n",
            "<HEAD>\n",
            "<TITLE>Not Found</TITLE>\n",
            "</HEAD>\n",
            "<BODY BGCOLOR=\"#FFFFFF\" TEXT=\"#000000\">\n",
            "<H1>Not Found</H1>\n",
            "<H2>Error 404</H2>\n",
            "</BODY>\n",
            "</HTML>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pJrlxkeTgKmM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M4q7LFIbgKmR",
        "colab_type": "code",
        "outputId": "8b08a9bb-0530-4a3c-cdec-c9db8bb72ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dataiter = iter(dataloaders)\n",
        "images, labels = next(dataiter)\n",
        "images = images.numpy()\n",
        "images = np.array(images)/255\n",
        "print(images.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 3, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XypwNC49gKma",
        "colab_type": "code",
        "outputId": "1bfd6008-3db2-49e7-8dc6-0d43e70c262d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "classes = []\n",
        "for i in image_datasets.classes:\n",
        "    classes.append(cat_to_name[i])\n",
        "classes[101]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bromelia'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "h7TGnyZjgKmi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # plot the images in the batch, along with the corresponding labels\n",
        "# fig = plt.figure(figsize=(25, 4))\n",
        "# for idx in np.arange(20):\n",
        "#     ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "#     plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
        "#     ax.set_title(classes[labels[idx]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0BT7PQWjgKmn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building and training the classifier\n",
        "\n",
        "Now that the data is ready, it's time to build and train the classifier. As usual, you should use one of the pretrained models from `torchvision.models` to get the image features. Build and train a new feed-forward classifier using those features.\n",
        "\n",
        "We're going to leave this part up to you. If you want to talk through it with someone, chat with your fellow students! You can also ask questions on the forums or join the instructors in office hours.\n",
        "\n",
        "Refer to [the rubric](https://review.udacity.com/#!/rubrics/1663/view) for guidance on successfully completing this section. Things you'll need to do:\n",
        "\n",
        "* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) (If you need a starting point, the VGG networks work great and are straightforward to use)\n",
        "* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
        "* Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
        "* Track the loss and accuracy on the validation set to determine the best hyperparameters\n",
        "\n",
        "We've left a cell open for you below, but use as many as you need. Our advice is to break the problem up into smaller parts you can run separately. Check that each part is doing what you expect, then move on to the next. You'll likely find that as you work through each part, you'll need to go back and modify your previous code. This is totally normal!\n",
        "\n",
        ";When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right. Make sure to try different hyperparameters (learning rate, units in the classifier, epochs, etc) to find the best model. Save those hyperparameters to use as default values in the next part of the project."
      ]
    },
    {
      "metadata": {
        "id": "KQo5AG87gKmw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uNc9IXmOgKm0",
        "colab_type": "code",
        "outputId": "0850f5d3-c008-447d-f4b8-90eb3ce3c2cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "hu0Nm5eqgKm4",
        "colab_type": "code",
        "outputId": "2d0da540-965f-4161-8ed5-061b822439ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2516
        }
      },
      "cell_type": "code",
      "source": [
        "# TODO: Build and train your network\n",
        "\n",
        "model = models.resnet34(pretrained=True)\n",
        "\n",
        "# freezing the features parameters\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "    \n",
        "# defining a new classifier\n",
        "classifier = nn.Sequential(nn.Linear(512, 256),\n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(p=0.5),\n",
        "                      nn.Linear(256, 102))\n",
        "model.fc = classifier\n",
        "\n",
        "# defining loss and criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.01)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.torch/models/resnet34-333f7ec4.pth\n",
            "100%|██████████| 87306240/87306240 [00:03<00:00, 25258262.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5)\n",
              "    (3): Linear(in_features=256, out_features=102, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "K99E9-UugKm-",
        "colab_type": "code",
        "outputId": "dbb70fe2-a172-49a1-8c28-c676439d1fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "n_epochs = 25\n",
        "\n",
        "valid_loss_min = np.Inf \n",
        "start = time.time()\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    #keeping track of valid and train losses\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ############\n",
        "    # Training #\n",
        "    ############\n",
        "    model.train()\n",
        "    for data, target in dataloaders:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        output = model(data)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # parameter update\n",
        "        optimizer.step()\n",
        "        \n",
        "        # updating loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ##############\n",
        "    # Validation #\n",
        "    ##############\n",
        "    model.eval()\n",
        "    accuracy = 0\n",
        "    for data, target in valid_dataloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        ps = torch.exp(output).data\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        equality = (target.data == ps.max(1)[1])\n",
        "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
        "        \n",
        "        \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss /len(dataloaders.dataset)\n",
        "    valid_loss = valid_loss / len(valid_dataloader.dataset)\n",
        "    accuracy = accuracy /len(valid_dataloader)\n",
        "    \n",
        "    # print train/valid loss \n",
        "    print('Epoch: {} \\tTraining loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
        "    print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(valid_loss_min, valid_loss))\n",
        "        model.class_to_idx = image_datasets.class_to_idx\n",
        "# #         checkpoint = {'architecture':'resnet34',\n",
        "# #                       'state_dict': model.state_dict,\n",
        "# #                       'class_to_idx': model.class_to_idx}\n",
        "        \n",
        "#         torch.save(model.state_dict(), 'model_classifier.pt')\n",
        "        valid_loss_min = valid_loss\n",
        "      \n",
        "        \n",
        "end = time.time()\n",
        "\n",
        "print(f'Execution time: {(end-start)/60:.3f} mins')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining loss: 1.092149 \tValidation Loss: 0.517074\n",
            "Accuracy: 0.8894\n",
            "Validation loss decreased (inf --> 0.517074). Saving model ...\n",
            "Epoch: 2 \tTraining loss: 1.080919 \tValidation Loss: 0.509512\n",
            "Accuracy: 0.8921\n",
            "Validation loss decreased (0.517074 --> 0.509512). Saving model ...\n",
            "Epoch: 3 \tTraining loss: 1.087812 \tValidation Loss: 0.516038\n",
            "Accuracy: 0.8914\n",
            "Epoch: 4 \tTraining loss: 1.087338 \tValidation Loss: 0.518119\n",
            "Accuracy: 0.8969\n",
            "Epoch: 5 \tTraining loss: 1.072977 \tValidation Loss: 0.522041\n",
            "Accuracy: 0.8864\n",
            "Epoch: 6 \tTraining loss: 1.068433 \tValidation Loss: 0.517627\n",
            "Accuracy: 0.9008\n",
            "Epoch: 7 \tTraining loss: 1.076862 \tValidation Loss: 0.520938\n",
            "Accuracy: 0.8921\n",
            "Epoch: 8 \tTraining loss: 1.088070 \tValidation Loss: 0.526272\n",
            "Accuracy: 0.8912\n",
            "Epoch: 9 \tTraining loss: 1.076524 \tValidation Loss: 0.511925\n",
            "Accuracy: 0.8933\n",
            "Epoch: 10 \tTraining loss: 1.073773 \tValidation Loss: 0.516469\n",
            "Accuracy: 0.8924\n",
            "Epoch: 11 \tTraining loss: 1.059968 \tValidation Loss: 0.519919\n",
            "Accuracy: 0.8908\n",
            "Epoch: 12 \tTraining loss: 1.074712 \tValidation Loss: 0.524004\n",
            "Accuracy: 0.8900\n",
            "Epoch: 13 \tTraining loss: 1.091946 \tValidation Loss: 0.519666\n",
            "Accuracy: 0.8876\n",
            "Epoch: 14 \tTraining loss: 1.105893 \tValidation Loss: 0.523417\n",
            "Accuracy: 0.8981\n",
            "Epoch: 15 \tTraining loss: 1.083736 \tValidation Loss: 0.518819\n",
            "Accuracy: 0.8917\n",
            "Epoch: 16 \tTraining loss: 1.073996 \tValidation Loss: 0.525118\n",
            "Accuracy: 0.8914\n",
            "Epoch: 17 \tTraining loss: 1.079638 \tValidation Loss: 0.528806\n",
            "Accuracy: 0.8888\n",
            "Epoch: 18 \tTraining loss: 1.091315 \tValidation Loss: 0.525651\n",
            "Accuracy: 0.8908\n",
            "Epoch: 19 \tTraining loss: 1.083970 \tValidation Loss: 0.520375\n",
            "Accuracy: 0.8969\n",
            "Epoch: 20 \tTraining loss: 1.078480 \tValidation Loss: 0.521637\n",
            "Accuracy: 0.8902\n",
            "Epoch: 21 \tTraining loss: 1.091630 \tValidation Loss: 0.507626\n",
            "Accuracy: 0.8888\n",
            "Validation loss decreased (0.509512 --> 0.507626). Saving model ...\n",
            "Epoch: 22 \tTraining loss: 1.088355 \tValidation Loss: 0.507673\n",
            "Accuracy: 0.8981\n",
            "Epoch: 23 \tTraining loss: 1.066659 \tValidation Loss: 0.523104\n",
            "Accuracy: 0.8872\n",
            "Epoch: 24 \tTraining loss: 1.068647 \tValidation Loss: 0.526294\n",
            "Accuracy: 0.8897\n",
            "Epoch: 25 \tTraining loss: 1.079949 \tValidation Loss: 0.518410\n",
            "Accuracy: 0.8845\n",
            "Execution time: 67.516 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "puOM6O-PgKnL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save the checkpoint\n",
        "\n",
        "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n",
        "\n",
        "```model.class_to_idx = image_datasets['train'].class_to_idx```\n",
        "\n",
        "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."
      ]
    },
    {
      "metadata": {
        "id": "Ov_sXDp8gKnM",
        "colab_type": "code",
        "outputId": "8a42b633-5c26-4e3a-c86a-5b400097d6ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "# TODO: Save the checkpoint\n",
        "model.class_to_idx = image_datasets.class_to_idx\n",
        "checkpoint = {'architecture':'resnet34',\n",
        "              'state_dict': model.state_dict(),\n",
        "              'class_to_idx': model.class_to_idx}\n",
        "\n",
        "model.cpu()\n",
        "torch.save(checkpoint, 'classifier.pth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-22d50a692ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m checkpoint = {'architecture':'resnet34',\n\u001b[1;32m      3\u001b[0m               \u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               'class_to_idx': model.class_to_idx}\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_datasets' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oluWV4NJnKSN",
        "colab_type": "code",
        "outputId": "657283ff-9246-44e5-ad55-ae72136a071a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "def check_accuracy_on_test(testloader):    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.to('cuda:0')\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to('cuda'), labels.to('cuda')\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
        "    \n",
        "check_accuracy_on_test(test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-eee3ff0fa788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy of the network on the test images: %d %%'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcheck_accuracy_on_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "NQDiV8LOgKnR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading the checkpoint\n",
        "\n",
        "At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."
      ]
    },
    {
      "metadata": {
        "id": "JzWhtmSUgKnT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
        "\n",
        "def load_model(checkpoint_path):\n",
        "    chpt = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
        "    model = models.resnet34(pretrained=False)\n",
        "    for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Create the classifier\n",
        "    classifier = nn.Sequential(nn.Linear(512, 256),\n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(p=0.5),\n",
        "                      nn.Linear(256, 102))\n",
        "    \n",
        "    # Put the classifier on the pretrained network\n",
        "    model.fc = classifier\n",
        "\n",
        "    model.load_state_dict(chpt['state_dict'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CDmGYkTQeW0f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = load_model('./nclassifier.pth')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c6tNo-5VgKnW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inference for classification\n",
        "\n",
        "Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class of the flower in the image. Write a function called `predict` that takes an image and a model, then returns the top $K$ most likely classes along with the probabilities. It should look like \n",
        "\n",
        "```python\n",
        "probs, classes = predict(image_path, model)\n",
        "print(probs)\n",
        "print(classes)\n",
        "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
        "> ['70', '3', '45', '62', '55']\n",
        "```\n",
        "\n",
        "First you'll need to handle processing the input image such that it can be used in your network. \n",
        "\n",
        "## Image Preprocessing\n",
        "\n",
        "You'll want to use `PIL` to load the image ([documentation](https://pillow.readthedocs.io/en/latest/reference/Image.html)). It's best to write a function that preprocesses the image so it can be used as input for the model. This function should process the images in the same manner used for training. \n",
        "\n",
        "First, resize the images where the shortest side is 256 pixels, keeping the aspect ratio. This can be done with the [`thumbnail`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) or [`resize`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) methods. Then you'll need to crop out the center 224x224 portion of the image.\n",
        "\n",
        "Color channels of images are typically encoded as integers 0-255, but the model expected floats 0-1. You'll need to convert the values. It's easiest with a Numpy array, which you can get from a PIL image like so `np_image = np.array(pil_image)`.\n",
        "\n",
        "As before, the network expects the images to be normalized in a specific way. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`. You'll want to subtract the means from each color channel, then divide by the standard deviation. \n",
        "\n",
        "And finally, PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array. You can reorder dimensions using [`ndarray.transpose`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html). The color channel needs to be first and retain the order of the other two dimensions."
      ]
    },
    {
      "metadata": {
        "id": "W1M4ILXrgKnY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "norm_mean = [0.485, 0.456, 0.406]\n",
        "norm_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "def process_image(image):\n",
        "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
        "        returns an Numpy array\n",
        "    '''\n",
        "    \n",
        "    # TODO: Process a PIL image for use in a PyTorch model\n",
        "    \n",
        "    # opening image with pil\n",
        "    \n",
        "    img = Image.open(image)\n",
        "    \n",
        "    preprocess = transforms.Compose([transforms.Resize(256), \n",
        "                                     transforms.CenterCrop(224),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(norm_mean, norm_std)])\n",
        "    \n",
        "    image_tensor = preprocess(img)\n",
        "    \n",
        "    return image_tensor\n",
        "    \n",
        "    \n",
        "    \n",
        "#     # resize\n",
        "#     if img.size[0] > img.size[1]:\n",
        "#         img.thumbnails((10000, 256))\n",
        "#     else:\n",
        "#         img.thumbnails((256, 10000))\n",
        "        \n",
        "#     # crop\n",
        "#     left_margin = (img.width-224)/2\n",
        "#     bottom_margin = (img.height-224)/2\n",
        "#     right_margin = left_margin + 224\n",
        "#     top_margin = bottom_margin + 224\n",
        "#     img = img.crop((left_margin, bottom_margin, right_margin, top_margin))\n",
        "    \n",
        "#     # colour channels\n",
        "#     img = np.array(img)/255\n",
        "    \n",
        "#     # normalize\n",
        "#     mean = np.array([0.485, 0.456, 0.406])\n",
        "#     std = np.array([0.229, 0.224, 0.225])\n",
        "#     img = (img - mean)/std\n",
        "    \n",
        "#     # rearranging the colour channel to the first dimension\n",
        "#     img.transpose((2, 0, 1))\n",
        "    \n",
        "#     return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aFaco6dUqQIE",
        "colab_type": "code",
        "outputId": "d1228b74-ff65-425c-dc54-27ab944d1a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "img = (test_dir + '/1/' + 'image_06752.jpg')\n",
        "img = process_image(img)\n",
        "print(img.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QAKNkxPrgKnd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your `process_image` function works, running the output through this function should return the original image (except for the cropped out portions)."
      ]
    },
    {
      "metadata": {
        "id": "cqvEJFMggKne",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def imshow(image, ax=None, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    \n",
        "    # PyTorch tensors assume the color channel is the first dimension\n",
        "    # but matplotlib assumes is the third dimension\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "    \n",
        "    # Undo preprocessing\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "    \n",
        "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
        "    image = np.clip(image, 0, 1)\n",
        "    \n",
        "    ax.imshow(image)\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YRMFUifSgKnk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Class Prediction\n",
        "\n",
        "Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top-$K$) most probable classes. You'll want to calculate the class probabilities then find the $K$ largest values.\n",
        "\n",
        "To get the top $K$ largest values in a tensor use [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk). This method returns both the highest `k` probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using `class_to_idx` which hopefully you added to the model or from an `ImageFolder` you used to load the data ([see here](#Save-the-checkpoint)). Make sure to invert the dictionary so you get a mapping from index to class as well.\n",
        "\n",
        "Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.\n",
        "\n",
        "```python\n",
        "probs, classes = predict(image_path, model)\n",
        "print(probs)\n",
        "print(classes)\n",
        "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
        "> ['70', '3', '45', '62', '55']\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "60HhOLAigKnl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.class_to_idx =image_datasets.class_to_idx\n",
        "ctx = model.class_to_idx\n",
        "def predict(image_path, model, topk=5):\n",
        "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
        "    '''\n",
        "    \n",
        "    # TODO: Implement the code to predict the class from an image file\n",
        " \n",
        "    model.to('cuda:0')\n",
        "    img_torch = process_image(image_path)\n",
        "    img_torch = img_torch.unsqueeze_(0)\n",
        "    img_torch = img_torch.float()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model.forward(img_torch.cuda())\n",
        "        \n",
        "    probability = F.softmax(output.data,dim=1)\n",
        "    \n",
        "    return probability.topk(topk)\n",
        "  \n",
        "    # Image processing\n",
        "#     img = process_image(image_path)\n",
        "    \n",
        "#     # Converting numpy to tensor\n",
        "#     tensor_image = torch.from_numpy(img).type(torch.FloatTensor)\n",
        "    \n",
        "#     # Squuezing\n",
        "#     m_input = tensor_image.unsqueeze(0)\n",
        "#     # probs\n",
        "#     f_pass = model.forward(m_input)\n",
        "#     probs = torch.exp(f_pass)\n",
        "    \n",
        "#     #  top probabilities\n",
        "#     top_probs, top_class = probs.topk(topk)\n",
        "#     top_probs = top_probs.detach().numpy().tolist()[0]\n",
        "#     top_class = top_class.detach().numpy().tolist()[0]\n",
        "    \n",
        "#     # converting indices to classes\n",
        "#     idx_to_class = {val: key for key, val in model.class_to_idx.items()}\n",
        "    \n",
        "#     top_labels = [idx_to_class[lab] for lab in top_class]\n",
        "#     top_flowers = [cat_to_name[idx_to_class[lab]] for lab in top_class]\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AHSw4i86rL5F",
        "colab_type": "code",
        "outputId": "f85a19b3-0f06-464e-a034-a33b21b90790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "img = (data_dir + '/test' + '/10/' + 'image_07104.jpg')\n",
        "val1, val2 = predict(img, model)\n",
        "print(val1)\n",
        "print(val2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.00000e-02 *\n",
            "       [[ 5.4739,  5.0717,  4.9717,  4.2241,  4.2167]], device='cuda:0')\n",
            "tensor([[ 67,  40,  25,  39,  76]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CTNguAeBgKnp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sanity Checking\n",
        "\n",
        "Now that you can use a trained model for predictions, check to make sure it makes sense. Even if the validation accuracy is high, it's always good to check that there aren't obvious bugs. Use `matplotlib` to plot the probabilities for the top 5 classes as a bar graph, along with the input image. It should look like this:\n",
        "\n",
        "<img src='assets/inference_example.png' width=300px>\n",
        "\n",
        "You can convert from the class integer encoding to actual flower names with the `cat_to_name.json` file (should have been loaded earlier in the notebook). To show a PyTorch tensor as an image, use the `imshow` function defined above."
      ]
    },
    {
      "metadata": {
        "id": "-No5Xdk_gKnq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Display an image along with the top 5 classes\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "def check_sanity(image_path):\n",
        "    plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "    plt.subplot(211)\n",
        "    \n",
        "    index = 1\n",
        "    path = image_path\n",
        "\n",
        "    probabilities = predict(path, model)\n",
        "    image = process_image(path)\n",
        "    probabilities = probabilities\n",
        "    \n",
        "\n",
        "    axs = imshow(image, ax = plt)\n",
        "    axs.axis('off')\n",
        "    axs.title(cat_to_name[str(index)])\n",
        "    axs.show()\n",
        "    \n",
        "    \n",
        "    a = np.array(probabilities[0][0])\n",
        "    b = [cat_to_name[str(index + 1)] for index in np.array(probabilities[1][0])]\n",
        "    \n",
        "    \n",
        "    N=float(len(b))\n",
        "    fig,ax = plt.subplots(figsize=(8,3))\n",
        "    width = 0.8\n",
        "    tickLocations = np.arange(N)\n",
        "    ax.bar(tickLocations, a, width, linewidth=4.0, align = 'center')\n",
        "    ax.set_xticks(ticks = tickLocations)\n",
        "    ax.set_xticklabels(b)\n",
        "    ax.set_xlim(min(tickLocations)-0.6,max(tickLocations)+0.6)\n",
        "    ax.set_yticks([0.2,0.4,0.6,0.8,1,1.2])\n",
        "    ax.set_ylim((0,1))\n",
        "    ax.yaxis.grid(True)\n",
        "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tvW-lpY-gKnx",
        "colab_type": "code",
        "outputId": "0ab17e3b-38ea-4b15-89bc-6a7568433626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "cell_type": "code",
      "source": [
        "img_path = test_dir + '/10/image_07090.jpg'\n",
        "check_sanity(img_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKEAAACpCAYAAABDAl3bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsvHmwJNd15ve7N9fa36u3b93v9Va9\nAw2g0QAIAqDETdxEURyREilZC8cjS0FPOCbsiLEtR8hjx4wjNKGw7BhLDoXl4MRIHokcURIXieIG\nggRA7OhudHf16+XtW+175XLv9R9V3QApAlpCUsMmvoiMzMq6mTcr86tzz3fOuSmMMbyFt3AnIe/0\nBbyFt/AWCd/CHcdbJHwLdxxvkfAt3HG8RcK3cMfxFgnfwh3HDz0JC4XCvy4UCr/817R5rFAoXPt7\n7HOuUChc/Ps63//XYd/pC7jTKBaL//IO9LkJnPzH7vfNih8KEhYKhceA3wL+EvgA4AI/XSwWny4U\nCv83cK1YLP5PhUJhBfjXwC8BC8DvF4vFf/F953KArwBfKBaL//b7vlsB/h3wMWAf8NvFYvHXCoXC\nIvAk8B+Be4D/bNinXSgUfn54TQHwdqAI/I/A/wIcBH6tWCz+n8N2HwJywPPFYvG/KRQK/yXwywxG\ntCLwqWKxWCoUCo8Cvwn4gAD+h2Kx+EeFQmEE+N+Acwye/b8qFou/93e+sX9P+GEajo8DzxSLxQLw\nPwP/x+u0ewR4ELgX+HShUJj/vu9/C7j6/QR8DR4E7gdOAL9aKBTuGu4fB14qFouP/oBj3gP8OnAY\nOAb81wwI+UvAr72m3buBXx4S8IFhu8eKxeJRYI3BHwjgN4D/qlgsHmdA3J8Y7v+3gAaOMiDirxcK\nhTtukX+YSNgG/nC4/Tng7kKhkPwB7X6/WCyqYrG4BewysIgAFAqF/wI4BPzqG/TzmeHxe8ATwEPD\n/Q7wx69zzKVisXi1WCwGwDLwlWKxqIALwOxr2l0tFovLw+33A58d9gPwuwxICrAH/FyhUDhaLBaX\ni8Xizwz3fxD4X4vFoi4WiyXgPwEfeYPf8o+CHyYS1orF4q1EeX24HvkB7Rqv2VaANdyeBv4NsFMs\nFuM36Kf62j6B0VvnKhaLzdc5pvV9fbZfs/3aZ/Tac08Mz//aviaH278IdIGvFgqF5UKh8NHh/hHg\nDwuFwpVCoXCFgYXMvsFv+UfBD4VPOMTYa7ZvEaP6gxq+DvoM/LmvFwqFnygWi69n1cZfs53/W/bx\nt8Eu3/ubxob7KBaLu8CnGbgT7wb+U6FQ+HNgC/hwsVh8UynzHyZLmCwUCh8ebn8UeK5YLPb/FsfX\ni8XiGvALwL8rFAoTr9PuY4VCQRYKhSngYQZD8j8Evgh8pFAo3CLiPwO+WCgUnEKh8M1CoTAz3P88\nEDHwBf+EgZChUCjYhULhNwuFwj3/QNf3N8YPEwlXgIcLhcJV4L8FfuXvcpJisfgE8Ae8vrB5BXhm\nuP6tYrH4yt+ln7/BdTzDwD14Yji0jgD/XbFYjBj4h18rFAqXgMeBTxeLxS4DkZMrFArF4fVZwPl/\niOv720D8MNQTDkM0v1ssFg/9A/ezAnyyWCx++x+yn/+/4YfJEr6FNyneIuFbuOP4oRiO38KbG29Z\nwrdwx3FH44QH3lswQojhJ4EQAqP1YG0M2hgEoI3BKINAoLUGDEYbpBHIwV6MiZAKjHTRjo22IoRO\n8MEHP0zCHyGOHb701O8RiSrS8hAmw6jzEA/d9eMsTpyiVi9hW5KgFzA3N08sNN/+xueYHs0xOX6I\nduMmK1e+jLRynP3R/5zAeNSaHWyqvPLtzzIyOcuJs6dxTJKL33max37svTy3+ixf+LPPI/H51C99\nmnotTTY/wnh+in63y8ULX+Dpp/6YWLUxMiKKImSQJOVM0IibSKG458Rhqp0KN1eWMUqjVYSUw9FL\nWti+T6wNtutwdOEolusQqhjX99HDUW7pyAG+8eS3aLTLGNNGWhbGgMGA0IN7bwkMIKREWBKEAKkR\nlkAbhZAa2xaAQZsYTG9wDYPHgcBCRQIVGXQsEFigHYSQCAECyfUnLwl+AO4oCaWUSClvk26w07r9\nvdAaYwzSMLhBRoCQGGMQUgF9UEnQSSwEkV/HGBvLHsFSfY7vu5tENImlEszOHsOOvobMaCLRQ2tN\nfmqS3HiWMAwZyWZpt1ukkxk2V7cZnxvj7uNHWSleoumFJP0MQdgjDgRrKxsksxMkLJcLF75LUnaJ\nOxVK62XGZk7SjT263RaWtlmcOcyJU2/niSefR4gx3vue96PjmKuXr7C5tksY2Ag7iSZEWkkeeODd\nZNMjfOXpL5LPeEyOpri+fgVhbKQlkVYCEGgRIqXAsXxOHD1KMpliPDPJ2uY62gDCwbEk0zMT7FW2\n6UY1LF9jCY84jhmwQSCtAQWU1gPySYEwAAZpW2gUrivQRqONYsA6DRKMAok1IKGwBnzWCtTgGWEM\nQg6NyQ+k3wBvChLe2r5lFfXQGkop0UMiKhSWlOg4BmOQ0kJpH42NtAJwmsQyi4lzFBYfIa01CyNz\n9BsNpieTjKbSvP+xn+Nbl/4j1d4GkXJw3REs4VFv1Bgfy5BIeER9RdL1uV68ybnTSzS3dul1W3gu\nxJFHJjdPMp0ljCOIBccPn+Tasxcxqk3Yhn4vy/6D97J68wYry0VO7D/N/PQxvvbk83zyEx/FxBar\nWxsk0h73nf1R5hePUardAFpcunCBQ4sPUurF/Nj7fxHRr6Eq23TaCRy3jyLEdhziSCPx2Te3wNzU\nHAnHp1quUIpqTM/NUeu0iY0mlUpQqpd4+eoLCC9CiBihrAFxhvdaCkAIhACNwQiBhRw4atIMLJmM\nkEZjMLcNhtDeYG0EGAFagDYIJZFaYDSDRRi00Vjy9Vl4R33CW8T7K9YQEN/315G2hRIGy7EGV23Z\naOlhOWMYxlF6BE/lSTPD4amHGHMPcu+Re6nuLVMqvcK1K88SNuGhkz/HmQMfYdy9i4QaJ+5KMpkU\nyaSPtMB2JJYHOJLVtV3m9x2iH2k0GmSaifEDNNtdLEeiJUxO7UNYGQweriVpR5pKW9EoVxChhQo9\nNrbb3Hfvo6S8NLYlMASsbV3BSeaYmjrDg2ffg+rDVDaFA9j2BHedfBhUjpOn3sMnfulfgT8BtoNn\nG+an8jx89l6OHz6MO7wfubEcih6B6jI+lePAoQXm9o9zdeUibloiPQthDxbpOliOjeXYSMdG2hbS\ntrCcwX5uWURrsM9gIYWLwEZgAw5CWwhjI7SN0BZGSVASoSUoC5SFQKJijYo0cfj66fY7mzsWYvBj\nhQTM0KwLLGkN/kYYLEtijEYTAwKtLDzbRWuDsB1mRo/y4JkPYkuLbz75hzR2FY3tDgkrTb8NnjPK\n9nodN7nG/kKBILY5NPsg9x9/H+vXG6iOwJtMEWtNGMWMZkfZ2d3DSzpsV2u0PRfXSxPGdSwnSSIx\nTlfbdDsBrivByTG9dJhqqUKtsYfr13F8j+pWmXq9gfRrHD80Sd4dQwaCRq9OLpPi6e8+yanTDzEy\nkmdt5Ty7mze5+/ARVq4/SeH0o3iqjFQNdqpVcvsLPHT/R3jx+T/n6IEp9s3M0m5WqZdrlOsNLAcS\nSR9lQWX7JrqksTwHIzTG1whbQwyW5Q38aGEAhUEhhI3hln8oQIC0DCAwlsFIg4UNRiG0QGCQSIRR\nwMACmsHpQFtIIxBDKxhrNWwrBv7U6+COWkI9/OFGAHKwvrVIoZECBBqBBhRCSox22T9ZwItGkP0s\ntvJ47unvELTrPPTw+zm8eAwTazQ59rZDRkb302gZpGuzsDRDqbpKr9GmudfEReI6HqGSdIOIMIwJ\ngogoNviehzY2WiZJeB7aCITtY7ARyqVd72IJh3ZHIRMevuOhJRAGOA50gzZIBTImnXRxbYtmvYlS\ngHGYnFjAcVzanTqGDkaEpJKzNOur7F77FqaxSaO0SRgHyG6fxbFRDszs49D+wxgF9VablbVtYiVI\nZnzCuEWp2aAvFJEd04rqNMIW2pUYayAqbGEjpD0QH3LgVxs5uPdCSqQ1ECjCMgjLgGUwFmip0cKA\nAGMEwsihoNEMncvhfgtpbKSxsYaL0Nbt5fVwRy2hZVnfM+zeGpaVUiAtpNADNWwkQthoDa7xOXPg\nEe6dS/LUC89zz9GzfOOpL/IXTz/J4aX3cvz4XXS3MsTKp1FpMTMzT2msRL/Tw7EFcUcRqQbVcgXf\nyZAZHaXeaZFK2NiWy43rNzhwcIlyvcLISBZb2OTyGRyTxj7QAeHiZbPUal1qrTrZVJ786AnqpacZ\nHZ8mxEZYiig29IMO0o5ptipMzU+wW9/DFRmMkPz4+z+GDhzKe016nRS9Xh4lMsQmycULL7K1s8rY\neJ75XB26z+HpTe46lEHFbVQYYaVSTB+cJZIxTXoI38e3XBAR7V6dbq8LlkF4McYYjLQGPpuMGDDH\nBmMhhmbIMHDrBsbQGj4fg8QwSDELxFA0G6XRWBgkAgkIBnEMORjVhs/UFpJYxfx1seg7SsJXCWgG\nIQNjBmpYSmJtMIQDZ1g6IGwsGWErTaMSMuUd48HCURLC4+H7fJ5+5U9YXr4EDVjMP4A2dWJdIugp\nFmbnuHj1Oq16l3tPPsD1i98mIfug2+QyBTot0IEGLREGVNhHRQG+79FqdYjikKS2uH59jeOn9+GP\np1FunrBZx3eaRFEaLz2F447iJbI4iT6xGvhU09MT7Ja2mZwbARTNTpter8PRI4s8/vjjnDx6mtCe\n530/+jHC3jYxEWcfvI+J8VHarSYXz38H3zekkzCSSuGmZsj4GRrlLPPzWRQdVstlAmXoihK1ZoMY\nhXQ9pKWINUjhoZXCdsBYCq30wJ0R8nZoRt8alAVoIbGkBK0QGBAWSAujFJiBsdBDD0rrAelukRkz\nNCwChFbY0h64U/r1ifimrSdUBhxXoDVoNVBe0gnRbosXl1/g2MwEVphgylvEVrO86+w/o6dDZlJz\nrF9p4Lh1lq8/Q63qs7BvnqSXQgUu7UATBl1azVU63Qb+1Bx+uoDRApQk6fm0GjXyuRztVodcLkOz\n3aFnSeyUBzJE6A4LU3m22ts0qk/g6v0cXryLfqTpWg4jeYd9SwdZvXYNjM25sw9w+fplju47gnZc\nOq06j3/rz5mZSZIfbbJ2pYJtC0rbFzh4IIuf9fncl75Co9EilU2SSAjGM4LpVJ3FxSye7XCqcAhf\ntsk4kmS/h5YJmlaW7LEzPP7Ct2jGbYghKZNMTkxTb+zR7pYHokOEoEOEjNC4AAgDZqiSMQMHyJYS\nywjM0GUyA54iDAg5eDZCSIwcHic0UlpDF2tgG2+R2Ej9us/6jpLQ3F4bnGHgWVmGwAnxglHstk8i\nM8rc0r0Ur2yDKmLsNoEJ6BOSSmdQssLy8heJpeHIkY/SCCNyY6PUWrtMjKWobW3QqVZZPHkOpXsk\n0jns1AjKhIh+xOWnH+f0Q1NEIokxEpl06YctVLONk0igVcRoShKGLfyRMWTCIek65FIpdkSPl558\nivGZKtngAcZG9zE6ItHdXTr1JhNzpzD2BCrsMzEyQSsMCcp1Or2IhYWTbN58HNFe4dvf/ArdXot2\nN+TAkTxTkwtYtmR6YQE7kaEf9unGHVb3dujFV/C8JEe8DJ3mOnuVZRJWlk47YmrqOE4jZJYchyaP\nkEqNksjkaIVNZtITZNM+nW6LC1efo2s3CESMMjHGgGVbt0vItTIIYQYRQQFDKoHj3B6tLGyMUgN/\nffgghWUN/syAQCCsAXEHIbfX58EdFSZCiKHpFoMwE6ANCGVh6w7nTp0hHWU5OHaM9779n5D0pwZO\ntB2Ty6eZnptAmQhhSwIVoXVMLpdi38IcS0sHSSZHiKI+9UaVTDKJVuDYCcLQkMmMEKtBJiCfTyGI\nEULhONZthW5ZEhXHhGGPdDpBNpPCdhwsyyKOY6SwMRp6vZBup0e9VUOKQWB2bX2VA4cO4XgJ+r0I\n10nRrHfpdft0ux0SjoCow/rNy1h2n9i0QUTslXe4eXMV23FxHZtWs0q7XaFeLdPr9qjVaoRBiOMJ\nrq9eQ1gCL+HgJR1Uq0Vrt8KYlyMrU2SdFPVyjc3VDeJIgbLIJic5eewsUvsI7SCwkGIQTrmlCge+\n+WsXcXu5FduVljX06a1hLHE4LAsxFD7ie477/pDba3Fnh+Ohw2osSaQV0oDUNlbsYCLJarHBXQfv\nx60bFpbuZ/bHFvmTx3+DbhPW1rcJuklOHznB/P4x2mGXdt3BFjHrm2ukRmyOHL6PSy89ge95VLa3\nmE4dwyRcpJWlGzYIlKLdLvHMU1/i3e/7BLFxKO2V6Lctcrk8ldoucdwm7u5S2q0zP38E100Qa0Wt\nXiXox1SqLbD7pCdsWp0a3Z5NPuszt3SYbgCT0/OEkSCKNN1mjLQ16YRHghquqrK1W8RL22RlCreX\nJp11KW2X8BINKrUKjU6F2PRJC4ex2TxBL2BkMUe1XObggaPIqEmz2aPdU8yMGfAzuCqPl53ASycQ\nQDaTJI4idAt6fUkqv4+3n/sgX/3u5xEyYGDKJAMzIJDS/l4xYcTwcQ33GY1BDvw+Ww5Td4NwDpYY\nxAoHDTFaY97IDHKnMybD36Q1gMEyEh+fT/3Ur1CpepQ361Qr14h7a2TTiyRGDvLht/33bG1vQ2Rh\ntMO1V8rMzPp4mRxjGYEjPCYnfNZLK8w4Lsq4dFp9Vq5eYvHYj2AJQWZknHo94Nipe7nywuNUtpbZ\nWb+JdHII45NNj9PpBPieBEfw8oUXCaM2SwuHsG2HIIoIw5Ag7CGFHqToLAGORb3aYHHmIPOLJ5ia\nW0QZC2UiPE+wtXWRZHaC6XyGamWDlfXr9DQkSFKrNxkbnWJudoZm6zvUG3sYDL12DT8hcHxBaW+P\nk4cL+JZDypa0ah1kHCO0hWv7VPu7ZBMe5UadmUyCWnmPsfERrq5sk0xkmJuYpRsEbFT2SKU90ukE\nrSC+LQrBQkoBRiJfkzwQUn6PcASJFmIQ/L7lKNoatMGoYXsG+eLhQPeGuLPq2ABCYxuJQuNoiQwN\nF5+6yNvOPMjubpWo1qe6t8eTm/8Xj73v53DESebHDnDjxksIrclnx7FUQLtWZ3zsAEIJ7ISD7dis\n724yO3+YysYN4n4X14oRImJsbIx2r8qxE4dYvfQSYdhjdeUm+5dOs71bodcL8VM2cbzLdN4l6jdo\nNUu4w3+9UhplFI1mBc8TCBmTn8yhLZe0LVlbKzE1fRAlJBpNpbLJ1JhPuXqBu/Z9AFsKri5fZbNU\n5d5zJ6iU1nASmlLtBtc3nmV+LofvJ6hX62RSSWYm8tRru8QxXLu2TK/fZW/vOuXNmwgVY6RFMp1F\n9B12/C3sRI7AUkRSEzgKW8eM+D7t+i7Si/C8LpeunKfXqyOkfTvWB0OhYQaS4tUvhn7eQLUABmFZ\ng723BYdEOBqtDCgxyC2bQejG8MYsvKM+ocJD4RBJh0hY9C2JSthcXCvy+FMvMn1gkaoRNJMOPdHh\nia//KVulK/i+QHUNwvhYrkILkAhalS1anTKdfpusn8NJjTN+4Aip2UVC4fLCc98lbQuy6QyJRIZA\n2+w/fIJsbobRsRy2p5icypHNpXE9h06nTq/folkt02qFlMpVQqWIlCaKDYcLB4h1CI5EJpMYYTCu\nR085GMcijBsI0WE05fPShee4tn0NnCqWHRA0y6RtwdbNGkHgks1M0WxtYcuY8ewscWzohX3iKCDp\nuiyMTTA2OsL41Bjl8i7PPvs8zb0d/F6FnO4yl7SZzimseI165QK93h713Q3iSovyjV182yKWAS9c\nucgzy99iq3sN7VhYwkZogSMdbGEjjQShMMRIyTC3/yr5bi2W0GgTISzAAiU0SgwD25ZCC4XgVTIL\n8fpUu7P1hFKB0AjTxzGSh+99jHtOvR1h5fAyxwmY4Z3v+3keffcn6Hg5enGfzvIFmhurRJZLKj9P\nq6/BCByjSac8Ou06vqdJ+JJ8Pk8bh4WTd/GOD/8UxhnlUnEZYSDppzDGZXL+ENn8NDvbu6yvroDp\nkc0KpBWTSU+wu9fF8jNYlkW1UiUKI6SU2I5Emz7STSNFGqEs3FhiG4dGr0MQBIz5gqmkxKiQVG6a\nx37ko6i4yYvnv0q7v4OfTKEJ8B0flwRzUwc5uHiMyckDZNJTLC2eIJ0Zo9uLUE4KK5Vju9rh5nYV\nKRIgXUKtkKZNvXSd8u5N9jYvM5YVhK0NJlKK9esvULzyHF3d54mXnmEt3CTwUkRmDBUlh/HCYVHC\nXxEQf1VcfP9ya4g2w4oFcas8TGqEBGM0xmiEeP044Z1Vx7KHsNo4tLH7HXImwb7sDBP+FHFk0WyE\njOcXmJk6wMEjp2m26uheld3tNXr9kH4QEyuN7XooI0BrPNcilXLAhCQTHgnfZWtni+L16ywuLeEl\nfGrVGrawsaRLjEO7FzIxPkHS88ikXTRdPFviJ7JYdgLbSWLbNt1eF9/3MNpgSUmnF2DZabzUCMYY\nHNsmDAMSCQ9hInwp0WHE8rUbZDMTzE4doNftsLu7RhT3kVYCadmUa20qjR6p9CSJxCgaF9dJs7NX\nB3xsK4MySSJ8sBOExqKvNO0IOpFBOD7CsrAdi0QqASok4UhcC5r1EnHQYXdnDz+ZQ8gEghE8e4pc\n+tUp0t+vYm+tzS2fj1eFiRC36jr5HlV8K4ho0LeCOshhDPGNsiZ3Vh2rUaLAxYgUeTvFs19bZnKk\nwoGFRTKpDOVaxJXnrzE3P8Xbjj/MQU9y/fIrUE5hpY/QblQRRmG5KWwp8H2Bn3QIgjrplE9po0R/\newWr12Bs/xLffPwrPPzYB+j1e0gp6XRjJuYOsX5zHc/2SKUSdDplbFfjeC6OM8nY6DibG8+jqluU\ny2W6nS5OKo02AqNzjE2dpHDiPrpBl1qrgfBtcqNJdLvM2m7ESH6G/ftPYPs5TFtR2WkzPjrK+s4O\n3a6LSffZLrWZmVnixD2PMD2T5Ttf+zpaeJy9912knASdegsnlWBzs8iF4gWSSQeZSrO+XSFnxbSV\nTS7hIuOA3FgepEu11uDmyjo7pSraeOTT43SCFIenHyY/e5K+1efl4h/R6+8AfE8Vk5TytoV7o9AK\nMFC/eihaUIMKMDmIbJthkYRlizcvCWNyfPD9v8Rs5i48YZOI2uzeWOblp/+SSBaZm38H9b0xWvUN\nlpZsVla2GJ2w2KmUmEgeQ0UthJug3umQH7Xpxr3BTehDp9el2+1RWl+hWr/JiJfhzJkHEEIyPTZK\ntVam06gg6XPs2Fk2dtZwnSTatEh4gm6/g8JFSJuj9z3Kd5ohtW4f388QKoXjCYxIcOj4WaJQInWM\nlIYTRw7Qqq6xvnmRS1eK5CcPMTJ9D4mREBVrZsfH6CQE5bE2x+45A5ZLOq1ZnJsknXJ54fI1fDvJ\nBz/0E3Q6AbVGQKu9xeETd1E4cy+271G8+CIHFxbYN3WUcmmXcmeXRhgyPyJJOzl0P2antY6OFaOj\nE4yMznLt5kWSiQVmchlMJ8VaeYVut4WR3iA4jcC6VSiibAYi2aDQgwyJkGitbj87CxvQKBUPgtFG\nY+IhIWMDSoOSKKWQcrB+PdxREvpdl4vPvsCqs86+uaOkLRtLakQyIK4EXHz5a3z8px9ma6/C9k6D\n3b0+3U4TN5kjjtukcrM4fpZup8n85BiNXoPZ2SlUHBDZEbaUpLOjlCurXCte5uzkKTZ21hG2Jp3x\nqFV3uLn8IidOPUx+bIZOv0c6kSEKm4SqztraCjPTh5gcPctPfvwIYadOEIGyY6IwIJMeJYoibNdg\no8hncty49jKToy4rK5ep1ndphYL5ww/R123S6RTt7ZBEIo8mTbsX0241+NGHT7K5UmS5eJ7dluLj\nH/4ZSqUu3V6EES67e3WORZKRfJZEwmVsLMva+jUWF08wv69Av5ai1dxjp94g5fax4x5W7OP5Fl5+\nlEt7W2xcfIXFhQfITx1gZi7N3MIsL+90sSwLSxpiHaGkGcgORw2C1kIgh0niv+oHMqi+M8NY4K3i\n41ghYjPIOqiBNY3jNy5iuKM+4QfvfwjV2sK1O8xOzxFFS9S6xxif+UV6YZaRjM0X/+w3UMEK3Zbi\n7P3v4+ZawNbmHq4d0O82mRzPMz0+jdQenpthd6dKpVKm0SgTqy4njp8hm5wiDmrcuP4ss7PjaBPT\n7/eJ4h7S7nHt5ktcXb7GxkaJZh1kNIOjponCJucvfJtWu0S7LXj55WUsy6Var9BoNRFYRFGPTMYi\nn3eI+2VeePEbrG9fYWtvE2yPXhBhgH63zv75PAabnZ02Z+5+lPz4OGcfuIvi5QtcPv8iu9sbnLvv\nDC8Wb3Lp2g7rWy2uXt1gfGKKerNGbWeHZ558nEplEzflsrlXZX7hBFgZugEsV6rcbFSphF1c30MZ\nWL65Tq3RwPUlp04cYv3mVdb2zvOVp/+AUJYRWBgzKO0akM25XZpv9KB8XwxDLLeq4I0xaK1f9QuH\nxIzjGBUr4jgmVgql1O12b1oSpj0P33FYWfsWX//O70B6hdG5iNiPOHrP29jaqWJZXa5ffwF0DMLH\nT0ySTuWo7m0xP5Wh3ShhWRZ7pTph39Dva2zHxxgolfdwHJ+xsRm6vTp7uyukvQQJx8e2HGKl6Os+\nxasvMz09geO4pJNZatUevpPHEj6VcoVabZ3drS0m8nl0GOPZLtIYlI4REqIwQEpBp9eitLdFp9sk\n1oZOJ2IkP0UQDoakXreD7bh0ewEIGyM1Ydwlkc7QC2MiZej0+oxOTCAsF41NLwgJwj69foubN65i\nVEwURWRzE9SqAVvbNZAunW6E8S20P065DbV+j3YYoXFIpDLMzc6xvrrCjeXLZHIWkehg2QIlXIx0\nQEgsbGzt4kQejvawzGCg/H76vJo5MehbZFMagUDpwefXLq8GuX8w7igJbxbbHJi/n9mxM7Tae/zl\nd3+bz3/zN7lWfh5v9jBvf8fHCHs1pC4RBmWQLg++7X3sWziGCLt8/UufYWLUoVQrodwEvZ5NvRYR\ndMH3UoRhjGX5HDp4AttW9Dp7tEs1Mk6WhJ2lryB0oBftUK5sMTM9SbcfkEpBIqE5e9eP8K7Hfopm\nNSRolrB1QKtaIWi2CdtdFF1IpBFZAAAgAElEQVTSKY9KvUqr2WFrY5Og36VcLqG0hSbJgQMncewU\nvpukWWugheL03afpBzH15h5z+ybYLtfRlodwPOrtHjfWV3ESSQI18LnavRp/9NnP8OKzT5P2U4zn\nJ9nZ6TM5fRzECCsbuzS7XbqRz6n7P8X40kdZa/rstgRBaNPtara29rhxfZXR7DTtTszU7EG0GicQ\nSQLho7SFDG0mvCk+8raP8uiJd+ArD2BYiqW/x6pprdGvsYhaa+Io/p7Pt5ZbZHw93FGfcPGeB1BV\nl7GFJZJbJfBSCEuTy9rk3TRmepGlY++leOkZjs1t0wsTJN0CzW6Na1dfwkl4fOurX+Tcwx/iyuoq\nthWRSo4Qx+MEdog/MkopqODlIJtfJOjXOX/h87xz5tNEyqa0t02jWeEn3v1hvvmdF9kq7XHP2Xfw\n1S//EcmUy+TUItpIHn30HZy/fJkoCAnjKjMTk9QbVSq7GyQzM8TKZ2Vljcs3bqIii3Z5E8dVeMkZ\nUokslq4TBS28vMSyPaRUpEYUidH9/D9/8Bf8wsc+yhc+/xm6/TKWn2TM2kfQDDFhRDKd4OSpE9x9\ncolr5y9yI+gRBh2Ucrn7obtJpFM8/0Ib4VocWjhDOn2I+UMu9eoKQRTTCRTddoSwPALLxxo5hOmN\nccx/Pw+d/QBCRnhein6gqO1dISH2+Nwf/DZuLoMYTQxjfzYgBjE/rTF6OCNPaaQSSCXQ8SD9KpRB\nDv1EtBpMnhpWzb8e7igJV1ZDbLfBVHKaI/tPs7FZJe4FRO0+Gzs7ZHIe+w6cYfHQKS68+By5lCI3\ntkpsLB7O/Tw3lpfZ3dqg373JeNohMBbplMX29gUWZo8xmbuPreY1ur0GY/PH2Vp5jma7irQDLKFp\ntzocPXSObz/+bZK2y83rF7nvnnNMjk+wW17j2o0XBsWc3+4zPbHASH6UXgzlvub62jZr15/j2Mm3\nkXCTHF46jpUQfOMvtgmjEGMEE+Pj5EYybG6u0+vVGR1zQQR0gyaWZdFudTlz5hyuP4r0RlFWjkYr\nJDfp0Wq2h9MqeyRTFuXtBpZjc999j1Fr1gmVy9XlNXKjFq1WiYQfc3DyFAdmcvyH3/8GjUqM5Y3y\nU5/4FK1+SKCg3e7gScN4JsfmdoWR1BjGabO2tsLGymVUq8XVi1eZPfswbs5mJ1hDiSbcVsivChOh\nDEYN8sXowTxwozUojVYKhmQdzhJ/85KQfotaY4fze9/kcOEB5o/ehWVsuvUG/b02zWaDfuzgOA4H\nD99Lc6/CM08+RWi6HNz/Y5x9+J0s33yRq1dvcPfpc6yWb9JsV6k11jBKkUkvkp+ZwhufI+clqFd3\nQSnarTZ+ZpS52UVGs4e53H0SI+scPbCfdrPO4SOnKS5fxE52SaTS3Lh+mYNzS7S7dTQOs1NzjI/e\nw6HFKaoNTavZYmt3l4W5g+xbOELC3qPbqbK0dBzPSfP888+RyflEKmJ+3/Qwg+AjSJEfnWdlo0FP\nZ3Aycxw4cgbd7NNol8llM1i2ZGV1lYTrsb55Ey99igceejfLK1tU6iWuXX8GKSEIQmzR48JL3yEI\n2+TnFzh590Ns1UqEWtALFbPz++hFPXaCBjXdwem4+KaLDCS6IwgDl49+8p+yFm1Q7+9iQoUlLYSR\nf0VcSAY5dBMrjNK3CSlvq+bBSwuEHISt37Q+oe7sMOp4jOccNlcvYYmB32C7STL5JLY/iE3Fwzkn\nUZzGkzOU97bYKd8gsPos7C+gTQYpXVQEnWZAyhvDdxNsb13HIcbCMDE1z+jYPiwrS6+vGcuPMzU1\nR6+r8ZI5qvUG5XKJMFZ4boZ+P6Lf7xCrgChWBFGAJQwHFqbpN0o0yjsY4xKEMV7CY3X9Bp1uxMnj\n96AiC9tKMpafJo4Fo6PjTE3O0mr0MEbQ6wbs7FRIuFmiUNANNdMLB7j33CNkcmN4CYkxAQhNJpOj\nVm1iWw5GKPZKu3SCHmEc43g2fsJHysEUzJGxUcp7fSDPibsfIpufwnV9LOmQSmUJI4WKBpmdkVyS\nbMplLDvH4cX7eOejn+Tcwx+mFgs2Ni5RLq9gyRALc1sdw2tqQM1whsmwGlvcUtTDNbe1yxuLErjD\nlrC3c56WSjI+I/AnxthZvsnc/GF8K8F26xqt9h77Fg7S6cYYJ0Gt12Np/wPslC5x8aVvsLm9wkd+\n/Ffw/RmWN65ClCXhTEEcUalWEHafvd1VsplxUskR3vv+T/DE175Bo97jyuXrBFFEu1Fjcv9Ryrs7\n3FjeYf+xgKZUWFaSsL9HvVZjbGKKfj+iunedVukKTz79Mo1mn5Nn3sNIboxabYV0OsfV5VUeOXeO\nWn2PY6cm8CyHjc0NTBSxu1cmkxtharaALRPss/PU6i363S5R0Md304xmxsik4cXL16lWtxkbGx3E\nIoOYbiskmcrgJhLECsI4oN3dY2xilPXLKVzHw/GmsD2Hcw+dQ1mwttUgnU4jhQ3aIePkUFYHN4yw\nwjJXnnqC1bUKqUyWU2cfJDGV4KmLX8bxNsGE+GGfVC7PbqsN1q1EnBi8eMUojFCAwhg1eDuDNkMr\nOJj8DoNJUeINJr7DHSZhp9ul3akQk8GqZshO7mf1xjr7jxRYOnQSx9U0Gk2SOY9uU6PsDvZIjofe\n/gE+/9nfpbJ6nme/82XO3P9jTM3NkbB89vYq7JXL9MMax0/NU9kuEXRbNNwcYTjBwWOnsaRNEAQg\nBXI0pK/SHD1xFKEVI26Ma0tmphbZ2mvQbnR48O1nMbHF+o2LaF2nG4CTSpPJpCFoca34BJY9zdkH\n3kY3bDM9e5BmvU421ef8yy+ipOTU6XuZnptnJDVCrAU75T0ibdPvRVS2ruFlbDBtrpy/zI2V59DG\no1h8kUw6hRSKZjsmlZkhP7GPXmhh2wl29sq86x3vYuPKCkcOTdENDE7WJTAQdEIy2TxuwiHlp6iV\nazRqVWxf0G0rdjYusb51g/d84BfwMjbr9W1MBPOTU7RbHRbGJpC9gKvba5iUNQxKDyyeUQaj1SBE\nYzSGW69bGM5XRg7mmOjBGxqEfhOTcL0jefu9D/Gtr34Rz+nyrsNncZIJ1lYucvyuc0QKlDaIIAbV\n4dDhfbgJSbsP95w7xysXv82TT36eg4cP443so9mtEpkeudEE+0eWuHT+KbISarUm3djhbY+8l+1y\ni2xmhGQygVGKXCbN43/8BTq186QSFtGL3+UDH/oVHnzgYbbLS3T6EUl7Ad/p0O31CXpNVJxGSIEl\nbYRs0OltoOjQax2k08oiUHhJm63aFkfOFDh5/DSVaomLF7/Nly+8RKvX5LH3vo9s/iSqB0lfkR2F\nkDLffe4pkgmHmak5jh27i1azi7Q9QBAKnwifdgjJXI6HHnwXrZrNkZP3sVu6TL2zyrHjZ4mMhe+M\nEvYDOu0KNVPBFpKRzCRB1CcKAnqx4O3v/ThbUUAijLi+fpOlmf34HVDlgE6zQi8OyOQztE0VZW5l\nQDQoM5gIb+RAKWuBMOJ26Oa1w/ffBHeUhEeOv5Na0CY/O8u+sSme/Oq/pxtFzB89QmUsSyTGSKfS\nRJ0mKgxwPY9qo4stUwh7jLvveTfPPvE1/vwL/56f+oV/SSeUWK6Hp+DCS8/je5Ir1y6SzWbY2qnw\nrW/G3HP/u+h2Gxgd0uv1qFdL/ORPfoTK3r3cWL7C6tXrxP0ara5DudqhcPwk2eQIf/6nXyHoRygN\nUjoszO/Hsmwq5R0UPbTKUq7U2LckGBmbxrR6xH6Hg/Pz7Gzv8md/8hlUvE3c7KO0pFmtk8v0SHoB\nDj0quy1m9t3Dz37yn5N0M7TaPfr9HvuXXOK4Rca1OZd/kHorZrtUAa3oNtap7TTZv3iImYU5Stt7\nKKuPMdBstfEcl5HcGK1GDd91qFZ3qDe3mM7PcPjQPlrlNon8OK88+13uPr3E1tVVKuur1Hs3iRSc\nfPA+brSvYSwDCoxSQwWsMLFBRwodAUZg1K0iBm77hoPX3Pz1hLyjwqRa7jIyPku7b1GrdejXG3hG\ns7t2g259k92dNVqtFqXyHlorur2ATDpHMpHFT+SpVuOBwx12aDZL1BpNgjAmCGIsaZNJ56h1ulTb\nbWxXsrm5wvrKDVK+hyMh4Tq89Pxz7FUb5McOcuLkI+Syk7RaVRxbMjE9RaQiur0GZ86cIY5ipLQQ\nUpJKp7Esi3q9jkBikHT6Edu7FbT0yE/OMTt7hK3dLsb4JLw0WkUEuk9kNP2+QRhFGOyxuXGN3e09\nsok5or5DvdVCmYjitVfYq6xSqa+xsbFKp9Vifm6WmfEJyns7oFt0O1soZSD2mZmdZXd3g0h3GR1L\nkkz7jI+OE/YDHMem222Rzfn4PoyPJMn4Hr7oc/fxRaq719hbv0LSielHML94mFKthRb2sI7V3BYj\nQgz8wlt1hLfyxq8nQJSKUer130VzR0k4t/8Uxlnkox//Fyj/IPtPP0J++gB2EHH5+W+iOmUkMYcK\nh+jpkGarRmmrQti32b/vJPef+VGW9t/L4txhblw5T1LmObCwQKe3x+jYNE8++wIHDt7F3nYTOxZ4\nruH5l7/DZm2LmcP7KLd2SNltPvtHn+NmqULkZ5heOImJRhlNTzGXSzHpCr702f/Awsg8P/2Jn6cZ\nRGTTI+ybXmJiNM9WaZtOd5SjR85w9MSjLC6eBgWO5+M7GebGp7j00jN85Md/hmZoUDKFsm1261Us\nKXnl4re4tHyefhgQ6i7tdkyz0cVym+THBHGvC3EP5fZ5ZfkGL5+/hJCGhQWHammHI0eP42UnyE0V\nqFT6+CMpNssrzM+PMTWTpd1vQKBxRczpo/s4MDVBqXSZS1cv0WzUiNu7rF95ltrqi/RbVZzkBJG9\nSCDmmDv4ALFJIqWD1gqhI3QUYAJFFGlUGCCVwo4kdmBjRxZWPHgXzaCGVQJyoN7F6w+6d3Q4Hp3I\n4fk2yoJ3feij9FsVdnfW2FyfoNOKsIWL1AHtRomUa1jdWOfgkdOMTozRbLeJI4uT596J6rW58EqR\n7Z1t2r0ynpvBtxOMjoxz8/oVztx9nNVrl0i6HkrD6s1NztzrcODYQ0ShzXs+dArlJNFIlk7fQ7/T\nYqO5wdLcKF//5heoNFb5wy9/iX/y8UcYGT/I8WNnyU+OE9CgF1t86p/+OjpOYlkJon6PdrPNXjVC\nWg7Nxg7Ccuh0NFLnMKqO5TqDSVR0KJW2kDLFXrnF9RurZLNjLBevUn7uErPT08xOL3F9+RXml6Z4\n4bmL/Mhj72J9bY2bV1+mXCnz2CMfo95J0+8LnOQYE7P76KvrFJdXSafy1Pb28BNtBE2eeOI5LNem\nUfdY3H8fvj9KrbqJ5+UpXr3CXfe9m+zkBAv3PUaz3Sadl4htRai7GCzCMIFlHIJeALKHRhLFAUKp\nQYW2fnWC+2AY/pv5hnc2RNPeJeprgo5D0kuTTqeZO3SKQ3fdQ9QOeOLx77K3uY7lGPbPTZDPpXjl\n4nexr2d5+O3vIk5Itnc3yaZzzC6dJIhChFSkvBy7WyWk9OkEES9duMzS/CSq3ceXLu16wM5mGyeV\nY27pJDeu30TJBAqLhcUlkl6CyekpPBNy5tQj1BuSzWqJkCQ//v6fZXN1G8f49OI0n/yZT2NElytX\nnqC0u8fe9lUmJ3MoMUbh+MN4ruTihReZmdjPT3zoF/nTz/0ORIYDi4ssL79MHPdJ5uY5dfcjKMsn\nlXPYLT1LL9ii2mgwOZ6gWlulXNtkZuIAQlVYv3mRza0L5PKT/M5n/nc+8uFPcWDxMFMz9/Fy8UVS\n/jiuEUTtJraqE8UbPPXUeSrNJmFk8+jbfpbRkcMIu0+p1sR1BL/6z/81T51fYaVa4uzR4yTTCrw2\nQdPCctKYXpKDUwVmJicZHXH43Od/jyiMByk6QKORr6m8HuDVaQNv2qLWwws5bBFy/dpN+m4aEY/T\nEZJO2yaZGWFmapKw28PCpt0zZEZGSbTLJFMaumUy9iidpE+Awc74yL4FaITyMcrh2NHTJDIpVtZu\noNwcvq/IZ0eZPfIQlvao7ZQh2KHeKvHCs1c4ePAojhYge1TjBmG7T6sX8s73fRg/Z7F2bQ3R6SP6\n/y9z7/lk6XneZ15vfk8+p/t0zmm6e6YnYwIwGAwyQBAEAZGSKBISFcqmvNq1Nrh27Sp94NreWsuu\ndW1ZXsmWqihLoiSKohgggULkDIDJmDw9oWe6ezr36ZPjm8N+aCh4i9Dupx3ef8NVz/s+z33f189h\nY3Ge4Zn9JOJZFpZvcvvmxwSeBUERy2pSKBb4wk//AtVaEVFxcV2H906d5ud/9lc5+dH7dHf0MXvp\nIqlUiqeeexXD0XGFCD4W6WQc6jqNao1LF6+TSGQo1Wrs3bOH+7cusrk2R0xVqFTqhEonuc0CW+tl\ndkwdIiJoeL5LVA4wm1tU1y/RtApkOkcZnpompfeSSmepNWoYzQZN1ySu6ty9lyOiZtk12IUcSiii\njtkSeeHwLzB37wYT04fQZB1Vsjl/8dtEQg1VjOC6DcIgRAhDhE+kpn8z4iWKIpIk/b8+Vj/Uf0K7\nUaNe3kCXAuTQIXBapGLbOyCF/BbZbBsBIaIgEdFi+IJIOp2mO5vGbpYpF9ZIJqKIooiqisiShCxJ\nBGGI64WkklkOH32Clz/3RQJ0orEMI2MT1OtNdE1FCnxUQSCTSWGaLTLpFLIoUCtu4DsVSqU1zl84\nTaVWptWoMT46TOgHxCI6MV2j1SpSyK/T2dbFiWMv0N7Wg6JFME1re+dEErDMJgLghy6eaxOEAhPj\nU0S1GJIkMdg3giDIqKrKxsYqtmmga2lsK6Rl+Ni2gK4lcayQiBalUFzH9208X8BxRAYHJlDVOGEo\nMzd3C8e2UUQB327hOw1so0a1uv12mUj10Jbpx7YdTKuBKMLo+Bhj4xNYlk0qlkTwRVRF2e79uiGV\nnMF43x7sRoDTsLhx9Rpba2v0dXQSOh5SKG53TsS/j9LffYr/v9yOH+pJ2JbK8FdvfG/bBup5HD/2\nDIJVoCsdxzRNHFHGk2Uc22IglsEONNRQ4ePTP6CjUyMUJJy5bnoGZghdG8+o47oWqpxB9GWshoAo\nR1DVDg4dfYW4Z5MvrtPbO0Y8keDtt77NkZ17SMXg5VefordrHM9xeO/t9+nokTG9OLuPHkNVRH77\n3/+f/Pe//j8zPDoCrQbr66tUVue5cv0CghThqWc+x4mn+3nv5B9TKMxiuxbf+ZP/gzCAiZF+QiGP\nG65w8/YVnjnxOVaWlxkaHGHXjv3YYoxCJc+d+Ut0Z55moPcwUiSFoqgEboT+njQ9Q3vJl5o4lNCi\nOlU7w6s/8zqBF6fVsnGEgJXlq+wYniaiK2wW1jDqeawgwrOf+WV8OU48kUYKSpTXVujqHqRs2vT2\ndeFYLtFYghAZ322jZbWQVRclyDPSFsc2dBbW7yDKOXZPdjE2dIhys8T6+gK2u62EC0IPAfG/glEM\n+aS1J/IPvVc/VAhPX77EiRd/gfff+hZmvcyf/MnvEoklOPbks/hKJ74oksh2EdWiFGstLLOOa+fp\nm+jm2uWT4Jqk2keQQpf+vj2UmiXyW+t0d0+gKB2sb6xQXXKRZIX2bBv7JyYwV5ZI+iHFQoFMOsqF\nix+g6ZsgiVS757k/v0K00+Pm8jI/99o/I5PM8s1v/geOHDqMHpHI59aISy5SzKGwtoJjr7GZy/G+\nW2bXzDMcOfQ8f/nDDUI2WFs5j67qzEx/DsOqElpN4okotVYDPZbEKSrUHR85EjI0NMRP9Y6yslxE\nFVXGJx5BViLoUhbBbzE2rSC6MoXSKj1dvezYfYxQlEnEYoShS6lYpK9bYXU5h2eL+IGOmujn8O6j\nyHKIVS+wVVxmcscg4xOd+GKUgg2QIBoRCS2bequA5ZlgrhFLiPg02FgvMbnjCJ29cbbyLS5ePc3K\n6hze9rL3dktQ+MRg+P8A7W86JdsWhp9QF01X/05qjszg+H4Cs8zFc29jeyZvv/s9nnnuS6TasrRc\nGdt1kUQRQXH44NR7ZDsU2ntGscp1ttaWKJcaxFMDZAYOEu/dSTrZQURvQ5JqJCOgKiIbayucPfsO\nfd39tJoVBFskmYLVO0vEUu08WLzE6socKHEkREYGDqBLCrdvfAhuCcMooGo+S2v3SUUkFEkhX67i\nhE0CocrG5h1yWwVeeOXnOXz4Zc5+8E2EwEBT01w4d4Ph0RkIY6gRlVAI6RscJdqWIAwkSuU8SUmA\nUEZ0bRy7woObd7AcFzmMsX/POF3eIC1T5/BjX0RWZCRNIAia/Pmff4OubIZ4LM7S/XUmJnYiSRr9\nA0M4gcftucsYzWV6O9LIgsaZsx+jZbrQYi0cR8I2YpQbNQS7RrG4SMsqUSnO4gdxFHWCFz/7s7zz\no++S7VIQBZF8oYFAGsLG9tS08DebecLfytH/7s3w7wtQf0JNrW2ZERYfXCHdNoAu9fKoKhJi8fG1\nc3zwzhs8/dLreEIG2w4IfB3XF3n22S9jGDXmbt0lkQxR1ChbpU1KtS0enzoOgoPj2IR+g+s3TnLj\n2nkatRJS4OB7Aiudoxx+/LP4AVRr62Q7ZO4tFOju6qZUzCPpUClZ/NQLz1EpbPDxxXch8Fi4X+Ts\n6Xsk4jvobMuQiMfoHdnDH/7pTSRNJQwCJKXCmbMnOf7EF+jrmqJUnMV0PEIMvNBA1DwCAvLFAh1d\nY0RiKVbXC+ixKJbR5M3vfZ9jR5/EC0Lu3rwKYkA23Y5raFz+4CbtfQeJdU6jJmXuXb/FOz/8LumY\nSGOzTLPRZM/BA3ieTRCK1OoGbe1Jxif6OXfuCkvrJfDjzMw8w92lB0y0K3SkE1QL89Qqeaqbc5Qr\nC8i6RzTSz/Dw40xOfx4xVWezfo2iYSLj0dXVye5dj6IoMm++/UMMs7ndO/7EO/NfVfh3yQz/UD1c\nIRJ1ZB/cwCemqyTbe8jlVugdHqOxVsetN6i2mohKFEHJIIoC5c0qeiLKoaPHcZoFFhY8hHrInpk9\naBEbSQSz5lAplLhx/gOa1hqS7yIQoCQyrJlb7JZcCBQ21yroFHF9k3RyN626hyoEOIGGHhNYzjm0\n/DaSCXj08edpS3USmD66EkMIRd47+QMMw0NW09iWh6pEMJo5ImHIzPRxTn2UQ1ajiIKOYW5rNTby\nWyTjImNOQLVpb4+KmWUqlRWKpQcIyjOIkoXvu0h4KEqTteV5HFskMyTjCyV8O4JrGzz/4gu4bouV\ntWX0rg6CWBbLcFCpk2+tIomd3Lx+Ct2T2SibHH78MFIiRrq7Ay0ep9ZoUsmvUavmqBllRL0N11VQ\n2nqZvT9Lpu8A2USURHsHEcHgwPQA6ViMSr3K7aVlrFYdQdoeZhAFINge7QqC7e6KL7hIgYAYygQ/\nqZ/jQqHE4OAQRaeIIwikk2Mk9DGWN/NE5WXWt1oosk5Sk6jUCwSeg6YKtGoWlmEj+grjY4+zZ/dz\n5DcN3vje7zAw1E9f9yTZjm709jaqK/eJagJWq45vhyiJGK7TJPRUQl9kM19AjSgsPbjPyEgP+dwC\nO6f2IisypUqTgweeYt/eKepGBFU2ybWu86MP38Mym9iuiaKH2JaFImsIQQN8n4WF20zt2s8Tz75C\nT083gafyV3/1NkPDj3Fg71E8V2RhYQlFl2k2y3zvnd/GcyqEQgoUD9dzkSQfWXIRPZvNtQ0m972E\nrCWwmkVEXWO4vxs9EsdxYceOxxAlGVENCDyZtaU7LN89z1buFnazgWmGPP/cFxHUDIPZCXqyu/BD\nkHUBt1xlZSXP0PgRXnjx8ywu5fn48veRYgrrG+s0Wyl+5rNf5fLFd8hv1bi0ehfDcLHd6ifypBBR\nFLbbckH4yeH3yYwh265G8RMnw6fVQ4VwK1ekWKjgqAKpqEGqx0XTYFB0kSaO4NZbbG1uEYY+6aSK\n63isLT+gWG8xPrkLEYlmy0DTsySSCjM7d1BrVvFFl5Jt8uhznyOsTDA10sOpk29w5vIsoe2giOAS\n4oQqTSeBjIbtRZmdLXH00DFkOYMoaLz0wsuYjovTslhZPsXFj9/F9fJEIzKC6CMqJq6jkIy1U68Z\n+IGDFwRcu3WTvUefZDAxTTwS48HiFs8/91NIkoBr1ZFlmUZzDc2L0dWVpmWVEXG2+7ISRCMxFCkk\nk9DxLAvPj9A93M3b736LavkWuiTi+RFcX+NnfvprDA3MMHdvkXS7TrpjlN37H2HneIIPT51ifbXI\nT7/2GpubdQrra6zeX2B85y7S2W4KhQrp7BgvvXyASDLKRh5aToKZ3V/ANByqlTyms8HZD5a5N3+D\nanOFSFQlEc0QV9OYpoHlWX+rABGE8G+UkwiCiPiJqCoMPomo+JR6qBA2WjUcW2b3wb0s3f+IwoM7\nNKo5uroyeHIHfZ2jJJIpGi2HQrlJKhVnaGKMNifAcV18u8jl69cpFAocPHCEXZO7yHalMB2PuBLF\n9hycoIf3f3QDo+rRkR4mV/OwXAFJjfHSF36JbEbBbDXxLQ3HqmM0c2yulikUqkx196FHFQpWi9zq\nMiIOkgh+ICOi4iLj+xn06DSPHjtEJtlG/0AHnp2gWm9ACHfnH9Df34soWzRaOT488yZb+XX8wCPT\nPsprr32VmV1PM3v9Ms8+9UWmpw+wsnCHwWwvvlOl4cOJF17le9/5Y+zQQVZE/EDAcbanbLLpJLOz\ns6SSWQLbZPX8u1wv53nm1Vf4wpf+Gz44cx4p082VU2eYmRhCFQTqxgaVjSoxPUV7Ry8IAqblYTSr\nYBo0TRXHljFtG1/16e47wFalhid7iIGJ4DgU6ua2+yaeAAFaRp3tAdfwE/fM37o1/2665lPqoUbN\nfvVnfjtcNySOn3iKWjnHyr1rGNUipY0lWu48mUwWSCArCaKpHjp7x4homU9kSC021xZZXr7Pqy+/\njG16zN65h6RAe3sHbZlBCltVRga7saw8H53+AbKeIJ7t5os/9csIoU6r2eDOnXPcvXmRRsknkUxx\n5MkTZDJdlNZXMcwGAY828T0AACAASURBVAKpzkEwXTbzD3jn5HeQdBtREDl44CUOP/IKtuMQhA0C\nFBRJxSwbRNWAanmVSCROoq2P737/G2xsnEVUbPzQRpJDDEMj27aLr37112m2DDLJHtbXN8hG4NqF\nv8Z2GqS7Rri7XMdy82hajGxbF23pLN09fejRCJVyBVVR0FSNfG6DqFUhHo/jJjuItXXT1z+CabRw\njAZRTSAIXFw0IEqr2iKQVHRdQxc87t8/S7m0gJaK0zJ90p3DKFI/GS1OVw/E4iXq9U22Nu6zZ2Y3\nIQK/+43fxbRaJNMRDKNBEGzrgl3P2TYxCOCFAZ4Ii7dv/thv8kOF8LOP/S9hvH8HM/seBVHGaDUQ\nQ5fC2jxbG0UWH5wnCPKkUjoIESShh/2HXqBhOmzml7l5/Rxf+fKrfOtbv09Mj2C5Pp4D/X1j2LaJ\nrAqIcgdjY5PkNwtMTI0yuWMP+c0K9WqZ82f/gpXVjwiVGlLQTxik+Y1/9Z9JJBP88DvfoNUqUa7U\nMAON448+i2l6hFKIFxoMDfTTls5gWzalco07t+/hCDH6e/tJaDB38wx9A8P09I2hRbKIcpM//KN/\nTX5rGT9sEQo1fEcFevnMy79Gd+8gCCopPUJ1ZZ5cbg5NF4mkumjrmcKUAyxjeyBVEkS00KVeKxP6\nJo1aiUJ+i8NHniIwTCQthtbZSyCKxHUNq1lHkQQC38UPJZxQIQwkQtPEdOrEYhE6kyqetUrglWjL\ndmKYcOHyIlMTu6k1qhh2gWishWlVMIwK+dV1bMfHFwJaRp2duyeIqjLpdIbOzk4kUaJarXPp2hWW\nNnN4IszPXv+xED7Uz3FvTy+Zrj5kzyeURDzP357MU6McOvwCg8PdnHz/D7FNj66MiuN6SKGHCFTL\nJfp6Ozh34RSB0KBulIlF4miyzub6IsmUhuXUqdslnMDjwN6nmZwYZP7+Xcy6gyJBo1pC8ANcCUIE\nvNAHUSTwHEyzSrm6RqFYxPVVlpbv0dbehyLFGegdwLIs5uduYllbuK7M9auzzOw/QeDblMpblGqr\nyHEwfIvxiUOIjsDjx1/jO9/5HQQxwPNrhLiIBHR29RCEApIkoWoqkUgMWYkST8ZItGUQRA8RhYgm\no4gWtt1kcf4266vLxKMRGrUyOyYmqFVK7J7aT9UOaAQyYeCx8OA+1cIW7ZkYqUQSP4wgalFkSUTV\nPWTdgdBkY7OEbxVQRIuVtQKd3WPcuX2fgd4OBMGkUFjA3ywgiQGlUh7Ptslmu8gV8zQadeyWwWjP\nCH29nciSvL2JEtN48rFHOXn+IosbG5/KwUM9CX/2pd8MG1WPkandaPEkNh6+Z9NqFLk7d58do2P0\ndiQRcDlz8g16uvqIpcbJ9g5RreewrDzvvP9dPCoEOOiyhKpGSSd7KJfKiEqAJcSwrAj//J/9O8qb\n9zj19vfp65mgt2eIhfsrOJ6No8q07JBoPMHrr3+ZwKzzb//3f46k1zCMOqqgIGttpNLDHDn0AqCj\nKhJ/8e1/z/R4goAYoxPPIqvtRGM2f/Hd38Z3TcSIhI9AVBrgV17/F4QkWNh8lw8+eJP81nUCz+XZ\nJ3+WofGnaBo2Bw8ewm5WuX76Q7J9PSBLCIrIg4UFqvktFhau4TiF7RwSaduvmIil2LVjJ0EIthun\nWlM49NizuLKP59u0ahWScZnZGxdp1eocOfgEvhRg20WW5i9jGEU0WSbbnmVrs0Qm1c2Jl38Rxxcp\nVark1q8ye+0kybiE61ZoNeqEfkCtXibT1o0gSkiKhNko8uyxvXRlowg+aEqEVFsayxdphSoffnyN\nt9763o89CaWvf/3r//+S9/fqwzPrX48mU1TrBkpEhdAiGhHQRINkogPTMvn42nnW8ssghWTS/SDE\naNRq9HZnqZbLBOG2vjdAwwskbM+mZZVo7xilVkoiuu309I4TeD7N9SLdiR58V6NcMRndvZ94dx9T\n07uY3n+EobFpNCWBGCjoiThrxVVapkXguNhBCdM0yRfL9A/2YjtNDuzby93rd6jXA0amdyMGHh+d\nfoOAFieOv8SJx7/MSP8BHtyZ58Mzb7Nr7wiDw7s4cOAwt2/dIqK0ceLYSzTqTa5ducwTjx/lj37/\nd4jHJRLZHto6epHUGLGoTstuMP9gjkB0EFWRQLTRYxqSrNBsWWwVCqytFXnyyVexDZfQLiOEIkND\nO/nog4+YmtjBUG8viu8QBg3m751FYztvpVGtE4ln2Xv483QPPMbG5haF4gaCWOXW1UsMDAyya88u\nRAnUSIRStUooSzi+yIHDx+gZGGZ1dZmoatOsbxJVJSKahhhuR5iZnkDPwBhPPf34//rjOHioEH5w\npvz1rs52ys0amqahyAIbayvcvHmNRDqL7dqEUhnPN0mkhxkcm0ESoCOVRhJEbN9DUnz0qIBhVLeH\nK0ONpt/B0yd+iZ/7/Nd48pmnObhnms62KFqmC8Q45XoVLaaiRX0W5q9x79YV1tYXIISBvhGgSlf7\nAAcPPE4sEuPB/F180SOgSaWygVFv0dfTi6YkqOcLOLbL9MxuzHqFa9duIMgJahZcub3I6maJ/UeO\n0dfXzbf+7D9RXHqAUbSYmdjFyKDG0ECcUx+9Sz63RKtRYmnlOjhNrly8S3fHMO2ZLm7N32JgdJid\nO/YT0buxPIGWWcA0DCyzhWHVsN0WTzz+GrKYxPbznL34ET39Q3R09TE5OcHmyn2kwMCw6ugRmH+w\niC+0M7TrccZnHiORGcJ2AiynwebyLZYW5hgZGEcQI4DLvTsXuT17hrXVBeotg7pRRxA87s/d4u6d\nGziOgaqJqIJAOplE0mRqLYdirYEbhviezXOfefHHQvhQ/wlVJcqd2WvcnZ9neGQH7ZkOBgYmadQM\njAY0mw7FUp2Dj+zDMnRqtRY7JyfZ2NikVW9QrTRp1Fp4gU0iotAM0+Bo/PRrv8b44BD37p3m9Nkf\nUq8XME0LLTbE137xf2ByeohLl84wd+s0YdikuLVMeTWkUM5x4JGDLC7M8uD2BvseOUhnthtR8BEl\nH9duoYQq6/O3qOcKfOVXfpVsbwZHcAhCBzXVwVd/9X9E0lV8X/1E1NnEMUxGh3exa+Y3cD2PlcV1\n7ty/RL1xi8tXLlKol5FkgbOXf4DtxohlEjzz+ecRJJ+N3AYjAxN845v/jheffI5EJMvB3c9TNXZw\n9uIbeGGDwIswMjRNsncUXYzy0VvfRAxbrNx/m+mJBO3ZIWZdn3rNpq2jnXqjztGjzyGrMi1DBFfA\nNFoABL7LUm4Ow7T58MKHHH3sSSo5mfW1FsNDu1lZnafVKCDQxDQsIloMUYBoJILn+nT1DOMLCoVK\nE9vz8byA9kgEXdE+lYOHOk+oKgKyAF0dGSyjhShIOE5AIt2JJMiEHuzftx/Hdvj4448RRAFF11lZ\nX0OLRhkcnqBYbrC2ksO1Q/xAIBqLMzo4yNVrH/KjU98itzlHo76B6zYZGupHUGTWNjdYWV/BDxwq\nlQKC6CFJAbIcEAQ2RquK5zm4lo9tuTiuAYEPgYcoiBAI+H5I4KvEElmSqS48R0RUNCzPxXU9bNfC\nNJqIYYimKtiWj0iCSDTO1NQUg0P92JZL0wBRiOF6IpKks2N8H0cOv4Lv6dTrJulMks5sG9GIxtWr\nZ4lGI3huQDzezejIDAIayVQnu3YfomVaJBI6tl2mO6vT0SZTLszj2XVGR0bp6Rsi095NOtON4wmU\nKjUa9QaNWh2j2cIyWqiqwssvf5Gf/uLPs3P6IJYlIUlxBvt3oGtp2jv66OzqJaK3EdUzJGLtxPUM\nvguGaZLJtKNH4wRI1FsWtuthGi0C3/lUDh7qSWgbeVIJBcuHRrOJZRtYtkJbey+51iK7do3xo9Pf\nRFUFHDdkYmoY3ze4fuU84194HVeI8tJP/RKnT73J3K2b7H/sCQ4fPMSVy2/xztu/TzJlIygBkhQg\nyHFOPPcySiTCtZt3iSS6kOR2qpZGs7gIkkCzaiPaFvO3r5CIjuO7IlE1DqFN4LioUhQ/SPLcy1/l\nyOETtBoWeryLjBtBCmM06gUWbtwkl1/CdR0UUd3OjRNFfF9FU9K89MLLxBSV2Y8vI8ptZLJjjE7s\nIJVIQBBitUzquTLvnnoP23X5xV/6NVRtkC+88gv84R98nbff+QMGBifZMX2A8YEj1PMhzz59AiEE\nJ2hg1JbozEgkdBFck9XlBW7c2uBzn/15Tr73AYPxKIGosbSWw6OOYPoEYYgsyZiWTbOeoFb16Ozo\nZtfYI7z/wYe0tyVIpvrJZkUkJUH34CCyr1AsbhJ4BuBRqxUIgxZb+TKxRJL1XBmUGJVSnlg0ieC4\nn8rBQ4Xw2vm3aMu0MTLUiyAkuHM/RzTWhu14DAx0srR8B8dp0myZmF6UUBYRvADRsnjrh3/JxIEn\nmRwb4/iTr/HY0ZfJFVrcmd3k5rWLBJ5HreHwNzFZluGjRVJIsszkrp3oUZ329i6O2CFOs8Lc4n0W\nF5aJSAqL9+/xxIn9uJ5NGNoIgUGIgO0m+NLr/5ThkUeYX1vj8oW/oqOjjRee/gzVQpHNu4v41hZr\nS6eQxe2M4TDwCZGRpQyxSA/1wlFytSpJNcXgzikiHf20LAvbFnDNCmdOf49y4QqyHkWU2ujuyLKR\nszBNEUXRsex1FpbKdGQ7GB7Yw2vPfQVBqOD5DRbuXsTqyBJ4AouLRVynzOBYjHTfEB+cO83lW+e4\nOuvzy7/8TxjeMchm4QF//ZffJhbR6Yi1E9VjmHZAQpcRMLl5+yyDgzEMw6G7p4vFxcsIksfy3Ap9\nnVmK5S2iURdZ9klmJKbGDqGoEptbRWw/ILdRIBmLkt+qk9Sjn8rBQ4Xw3v1r9Ha1USrfwXMVuvr3\nEonYJJNZjLrJ6tIygRtHlhPoxKk1JOLxKILvI6kGC/dOk19ZJKJ7vPDsc/iOTUZvo9G7h4bpE21T\naJbz6JEYuwZnMOseQVDmze//Gc1WBdeqM9zbz3Of/RKd7cOkk0NUqi5hkEaPRZA0i821B8iBiU2c\nV175VSbHnuDS1Y/4+MIHOEaJdKYPSR6gvSeJtDJHy9EJhChu4KHLoyTSGaZ27GVoYApClfV8Ec9u\nkOjsJ5XsJAwrPLh7hfWNeYrVRSTJQVETeL6CIiYIHAnLXMWyDA7se4mFB6fp7xsimY5gmpuYVYip\nMs1GlaHhKa7duEJ31146dg/gOw7L63OcPPk+r736FXq64yyvLXD2wgc8cfxlBnof4bNfiDF/7wax\n0CKiRnAdFcOwqTRcIukkd+cX2Tuzk+tX38MyN+jo7OTEk58hFpXYHeymmF+kWi0g4DIwMk6tXKRp\nrJNIJNAUh2bDYKC3D1+MfCoHDxXC17/66+Q2H3B99hyeD1q9ju3IROLdmFaTfXv30bDq5Msleron\nadYN3JiOFg/ZKtwhEKLkgjU0PeDGrXO0q1F0LU5f707+21/7Ohu1CtWN7eXw9vYemrWQcvE++yYH\naZhR7txbYX19jj/60016B/Yhy3Hu39N55onnESwfwbe4f3cWAhU/yPDM06+wmXMZHZxAReTeravE\nY0kKDZuIEmXPzEuMjR1j957jJGJJrNa2Mi1ExLa2lSZ+KCHHYnSNDpDOZvhPv/svCYJNXL+OrPmE\nXgRBlYhKXUTVQTLpDL/7X/4NR4++QDrVTbPusWiu4FghB/Ycoea4rFdqZLNZUGVSbZ3cXrhB5eKP\nkEQPLRqiRoYIQ5VEvI94xGJtbYPFpXuMj++hu2sQApE//5NvkE0miChRent6kQQFSY6w78AT5NZW\nyGT6uLR4hWK9wO3l26hhhKgm0NuTxg88duwYo9EyQJLp6e2nWq3Q0R3DswXK1SqmaXwqBw/1YnJr\nbplyxSEaG0CP9GBaMrFEB2Eg4wcWekRFUzUSiSTDQ/2UC5t4gY+m60QjOqoqIwoiruciqxoBJqXK\nBmubi9hOk53TEwyNTZNu60bTo4hSwMraLJevnObS1XNUGmVcwaPRLJMvLlMorZAvLNNo1FAUlXqj\njuMFiFIcPxRBCFnfWMGxW6STCQzb4OSZv8a0C7TMCs2Wge/ZJBPdNBohfuggqgGO36Jcy9E0S7Ra\neTa3loilosiqzu49+wEIAxfPswEJWda285glD9uuYLQKIPqfBBZKxOI6XdkspXKZyemddPUPkOro\nolgtcPnmJSr1TdSIixYN0aMa8UR8O8JXUIhGElSqRc6cex9BcJElHT2SJNPRi+MLDAwMkMttUKuW\nUWUobC6hiArJeBu93Z2kUirpTEAyFiEej9JoNKhWqrzz9rusrKzieD5bW1ssPlgikYrT0d1JJKr/\ngxw81HfCd97a+Hoq00+5ZnH46Anasx309HZjGFVKxSXK5U3q9don0VkmtxZus3ffIe7euEmlUkUI\nI3zpZ77GE088zdGjz+JYAbKaxDF92rJJTKdKZ3cv0ZiG69cxzGXOX3oHR1SJJHqZ2f8iJ578MscO\nvUR3zxiG4WK0mjSrdURZYXR6nPHJKeZuPkCJK7R39iIIAd/9zn+hp6eT/pEZbt49y0svvrg9pVxc\n5jt/8TuMDE1h2Q5zC+f48Mx73Lx1laHhfnzfY3XpFPniPFYgsGfnY8zs2Muljz/GMJuIso0sZpC1\nKIpmYrklbs1exXHr9A2OIksxVtduEYmIJCKdWIbE8MQMYkSnUK2ALPPU048ze/MKiiQjCRqhqLJz\n5lFEMcbyyhyxmIasNUm1CdSbTSYmDqJqUZLtWfbunEEOAzzPBTzuzJ5HMDdxnHWWl67SKOWwTQMh\nVDBaBp5nockC5WKRUrnEg+Vllh4s0jJMypUK65vrpFLt9Pb00d2T5bmXfvw74UOF8Df/9be/HktB\nbmuDK5dnadR8Rocmee/9k5Ty85hOk0AIgIDVpXk2126STCbJdozjhhLHnvkMajKCFwicfOtD+sf6\n6B0cIMBlY32NhKZz/vw50vF2QidKqZxnbu4Bjxz9DL1De2jvHCAe374ANIsSSV0hGvURhTiIITv3\n7SKRyrB3z2NcvPQh5ZLFyPAQF858n7tzH/PI4WfQpBTpTIJEpBdFqPODN3+Pu/dvMjy0i7SapSvd\nw66d0/iCjROa3Lp9ElG0WVu6y9DwBLLewf59+6nWmpQKdfBjPHb8s9y7PwvYmM0SgiMyNrEXTdeZ\nvXMF03aI6j0cfuQJmjWbTFsfyVQHN85fxfJCpianWbq/gCpopFMD9A/vhNBn4d4dFEFED0VEr45d\n86hWfRRRxTF97tz4mHppgdBfwbO2SGgOgdggoEIyCfv272V6xy76u3Yy0D9Ke2cnkzsnmZrcgSqK\n6LpKEHo06gam4RLPtBO4Buur87iBy5de//mfPAgvX6p//dzZC2hKkmxbB6OjQ2xsLmFaJcqFDWpG\nhVqjQq1RJR2LYFob3Lp/m117nkJTMjiWg2E6vP/uj3j6icdJZ1Rsu8hfv/sH1Cplxkf3s7aR48qV\niwyNdGOZPtlkB2FYwbLWebBwhZtXr9Oe6MNsliiVV7CFFgePHkWQHWbvXiWVSqHrbWSS7SzMbzGx\nY4QbN9/H9xtE5TQd2WlETSGSioAscOrc+7S3dxFRY8RjMo5jsbXVpNYsc3fxNKKfx3GqCL7N7dn7\n7N5zhIYRsGNqL7O3l/nH//h/IghEVpeXEFHJZvrIZscZ7DtCXG9nz66dHDpwjJ6OEe7d+Zj33/8L\nxsb34dka2Y4OHiwtEotGmZ6cwXUkwkBDUWLcmJ1lZHSY9u525hceICrQ3rODbKIfq2lhG03koEWt\nvEapmqPRaNIwTErNBo7vI8kaeixFJJ4mkciQzAxhewF+EBL4Ao16g4UHczRbNSxre7i33izj2g1G\nhvroHxzg5c9/4SevY7K8ssrY8G5MwyKqy2ys3eP+4h1arSqi5BDi4foCfuAQ6c3gWBDKIkbTInR9\nHLtGfrXFjolJbNegvLzIj069QRhuYDoGd+9fZWp6P2E4wrvvvcmemcfIpjv48Mz7FCtLhKLIKy9/\njUppmUptnrtzd/jyL32NZFuUt/76fbYKi5w/+0O+8nP/glS6G1l9gGmHHDh4lGJhidnZyzz5zEHK\n1RoDIghCL889/YtIoYTT9FiYv4tpWPh+mnR3jEwmSa7uEwQ+Eg6Bt8X3v/t7fObzX6NY8fhH/+Rf\n0dUWY/nBBlG1D1WXGB4YYdf0fiJqBrtWwHVzlDZaNOsumUyZlz83TL1yk9HhI+hD43x49i1ScZVM\n/xA7d3dQ2FzH8VpMTPSxWdzAcGXauzpJtWn4apSNVgXHcensSOImdGyjjamhPeiKiuNs35DrjRKr\nK8sU8grloo8olSg0V9kqLvHI/nE0KaBYrtFo2XiBQxCEf5tx7Lke1Wpte+/kU+rhRs0KkEwkIRTw\nHAvLbiEIPvF4BE1X0KMxIpEkmpbC9zUUpYORof14poumemzlFvF8g+6uLjzfY+7ODSyzgSRIIHos\nLF8jxMH3fQQUTKOF5Zn0dPcT09LMTB/C92VEzWdp9Sa2WyOixAhsj1o5R+CWkMM6166cxrSbdHR2\nIIoa8XgnlYqL64Pnm9tCdi9A9ELsloNj+Wh6FElW0fUYmq4wOTnFUydexgsihEIEPwxAdNjM3adS\n3kBRRDxPwLJM7t+b58C+w7RluhkYnCCZaieXW8ao58hv3KOQW8A0t8hmouzdNU1/TzuEBh4WPT1t\nNJpVREVB1SM4tkmlsslWfolYQkZRfGRJwPN9Gq0GpVoRQfIwzQZeAHagsLZW5tadFcplG8OUQUyi\nqR0oSjuIcRotDz0e5YlnnyLb1YYb2Njuttvb830CAgJ8JFElqicQkBD4CV357Ozqoi87wPKDRcrV\nAl09MRKJOK2mgR1UwdeZ2XWUtvZeYlqCsclDeE4cwTOYvfUeLacEUg+ua4IUsrJ8B1kQULUOTK9F\nw7rPlatn2TF2kJ1TR6nV1/GDEt0944wO7UFWE9iCyt2ld2k4q+iRDI2SgaNZNCo5VKVAKMhcu/w2\n7R0pYokuqlWLiNbPI/tf4v7SCrZTYGX5Dr5xHNNaYPHuabRIGj2W4Nih41iGixPahARkUzO88trX\neP+979Oo3UXAQaTKj975M2b2P8fYZILy5hL5rS2eOH4cNZJAUuMg6eRyRVJhHcc1kEQB03J4/+1L\nnHznGqI2yKOPvUhPOkVnd4yrl+cw3WkSkSRbpQ1q9Qe0wirWloMeCIROAl8SiGdHSUkRyvebTAyN\nMDS+g2hXjNzmPLVyCVGB5rqNFpfJdKcJfB9ZgbjjU7AsyvUt1moryKGFqASIokQYSCD4CIKEKKp0\n9w4zOTFCV9fgp3LwUCFcW1ijt3eI0fEuWq0YA+PjpPJbGI5Dy1jBaLbIlysU6wWM+gZakEUI2xkf\nH2Bseifl1gbt8X3YVYtbyydxwhphGOA33e1Ucj/Ebpa4ef0CfhBHlIqoik9U7cF3ZZ544jEWbp7E\nKC4i2GlQEzQcE1FJMjw4wdLaFsgevrLBqVNvceTo61y8/iMO7z4AQorRjgFiQYSxvp203Dpu2GDn\nI4/ieR75XJWyFTA1uQfLrvJb/9dvsGf3Yxzdc4D9O49x6sIiYWhse50FgVQ8RbG4TmmrgBcGBEIE\n348zNHwAN3CJd3ejC1lmRp9E0mQkPc3VC5f44Zu/RTabwnSgkbM4sucYl05fRg4CpDBgcno/tUo/\n166dIqUYBK5BiI1Eikem91Cs5VhulrBdh7aODsTQo9LKM5bQsMsOpXoZw7G4ePYqomiCGCAKAkgx\nHtl/EKtg0ZaJEtMSZFJtNJoQhA6iGEAAdxYXaNgms7fv8C9/83/7sRw8VAir1QbFQpFoPMmVaze5\ndW8FWVFpWS6SnKPlr+DZGqqkISGQjERoS6eJpSQuXHpAoVxm99QQqUQEyzDwPbbtjIKPKNoguJTy\nHxMKOqLaw7HDn6VYrmE0Laamxjh/4Yds5K4g6jECJ0KsfYChsRlyKyvsmNzH8voZwtBHwCSwc9iN\nO7SKW5RLOdLpNJurJYSKQWdfF/VKFU/WSXdPYFkGodLJcm4TWYuRiMR49qnP8uYbbzI+sIOOzj56\nOkaoFHL4gsz4xC5kUcKx6zQaBQ4cOc5GvszQ2BjRuMLHVy+TbYsT1yP8x9/7LZBcXv3cVzj26NP0\nD4xx7uZZGpqFl7/F2kqNRrOCLKlsFssMj41x7bsXmBqfoFbNISgBspQmlR6iVjSp1QXa0yPUmj4N\nI0CLZ1hd3SIVl7HqFk7o0NOt0rQLINcRpe0M47AaZX4uJK7oNN0GzVaNru4sYsHHcVuEYUhCjpEr\nb7G6uEhMVj6Vg4cK4SOH9nPp2nnGxjuYnOnj8tUr2E2b48ePc/rMR1iCz6P7X6E3O0qr1sT1XTJt\naSzL5cgjn2H21g0ikZAz5/4SUTTYtWsn8wtzWNb2o++2Y9khECWeffY5Brp3kyrXGBnqpjMb49yF\nP8L3tmhUoySy+zn25GcoFMtE9BiJgUkIdcQQNFFBUCwqpVu4VowTzzyN7bVo1Q0Wl7bYurPKVlHC\nalVpNovYThNJ0HAkmYW5JM8+8WXSmQG++iv/lNu379LXlyKidBCmowhSnL6eaeolC8+vMz93h2y2\ni/6BNqZ2dPHBh2/ylz/4U04ce54du47wwiuv8cYbf8o3v/UfEPmPvPj8L/D0M09yd+kmuaUcl85/\nxGOPHefO3G2GRndguU3WthYY7J+htFwnEkvQnk7j2YBg0pltRxRDtoorBIqB50vIsoDjuwSyTCqa\nRhJMXnjh88TaFOqNCg3LJNQsBNfEqTXY2lynZTTQHJVIRMOyWoBEQEAqlaJlNNH0T2/bPdSLSRg6\n2HaTEJFILI6qyMRiGrduXYFAQpGyDPRPYhk2qysrtGc7kBSBB4vz6HqcmV17WV9/gGWXqFbzbOU3\nP9mBlRAEFUWOEIm0o6ntjE88gieIuL6HrIn4gUOrVcWymgi4dHd1E9EiVMtlZFFEEGQkMbItaQ81\nfBxyhWUSiQxqbYWO6wAAIABJREFUNIasq0TjCcamxpjZPc6NGx+xuHCJzY1ZyqV7FAqzlAo3yW/e\n5MHiXeLJNmLJTqq1Bul0O42aSTTaRm//OEKoo6lx8EL27t6P5zTpbI/SqG3y3tvfQRabrKwsgqDQ\nNzDO2Pg0mUyaVFrm9Ifv0aw6jPROsJUv4wcwPbUTo9VECANss44o+wSSR99wP2NjU3R29JJIJonH\nJcLQwHZrqFGfXGGRWm0TP7CpNau4QYhl+ZRKBpKUoDM7TmfXNMPDhxgd2YssxKlXm5gth9AVaDZr\nFArbyaptbe3EUikCUSAQwPF/QqdoKvUWBw8fY3V5nXQyxqOHXsQ2W6yvLjMxOkWqs49r189Q2FjB\nsi32Pz5JNKYxN3+R0eFuLCtkYscYK+uXQA4o5gsEfkA62U5ETWG2HFpilHhkAE3u4M/f+j2ePPEC\nIiLFShE38EHYXqofH9yBZ5pcPn+SxLFncdwKXX1DOHaNlmHiYmJaDi8//RyO7SIhcunCu3zuS68T\nBjECSnhiC0SFEBMBlTBQEEWR6T07GRjs5eR7HzE4OE4klkKLZ3B9mXS0i1qpQuCGpNNZTN9hq3Gf\nf/Nv/zvEsIUgWEiiyvLKLUIlRBDjPPnE5/n2N++SiLXR2zvJ/Nlr+IHPi8+9yoOJEf7wT/6Yo4ef\noVgqYG7k6GxTkAFdS9AwG3S399PbPcjcvYsUyksIYshWcZ215Tl0LU5n/xADmVG6uyZIJXpYz82y\nvnYP014inmojkFTslRqSISMYAZonESoKvp4gCAJs22Irnyf0TWzPRRAUxHjqUzl4qBAK0RDDrZBu\nk2lUC9RqAqoo09M7Qst1EMUkgR8wMDSI74o06iGJRJp4vJ3Tpy8wProfWdF5+vhXyZdWyaZjRHWN\nK1fPUa1s4OMQBDLT0yNsrl8jn7tOVH2eerXA2vpdwsBCECwEKY6iyISBQ6GwSa1axQ8MLNNDlBRE\n0SPwFCCCpus0ajVu3jhLvrCyba8PI0QiGUyriSzIKP83c28SZFea3ff97nzfPL+X8wBkJhIzUAAK\nhZqrB3azyW5SEm3ZYQcVYZnhoBSm7a0jHObKGy8ctiyHwkOESFESm82ZbA7d1dXVXV0DCgUU5kwk\ncs6X+ebxvnfnwYtEV0sMdWmJ+ja5zXj3xHe+8z/n/H9aEtsSkIVpXnv1G6TTk/zRH/0hvUafKy9/\nCU0v8g/+k/8WzxlTrx4w6LSwrTGGHeLgsX90SBD4hIGNrHh4vkjkm2w+fcCp5StkkhmKpUmy8UnE\nII9l93HdIe+/2+TVt17ivQ9V2uMR8bjGrU9+QjZhc/f+B3hBgsr0OV64soiISN8cMD05TRhFuHZI\nt9tDkBUOD3apHR1y+/YdEBVUWcXoHxFPeESyj5SQyOoOnmUQBDaKDq4V4NsWqqozPTuHaZls726i\nKAqSrCJpX1Dj9Fp7E2PcRvZlFDlGuTjH1uY+L7/8OmkhSzKjsbx8loW5Itl4nkYvoNv3eO2tbxK6\nJrZt4/s+I9Nhd2dAJx6wsDDH4uIVnvgjBqMD8sk5zq6e4Nvf+R0iv48ohPhewObGJtl0CSIFSZ/D\nHNtUJvPcuPESvufjhw7JVArDaOPYISESsqTh+x7tTp2Hjx/wpS9/nZ29OvlMgVRyGsdpE9NzBGGA\nKsb50pf+CyYml+k0x/geXLt6g1Q2Q6PZRddkivkc3XaLwcAl8DkG3UgBp06d53B/TP1ojSBwEQQf\nWTZ59OlPOLlwmp7hMTN/mXxqmtpek2Z3Cy/o43dDtjeLzMwsgCQhyXFeuf51jO4ea5vrfPmr3ySb\nX8QNfar7T/GiMWsbWyRiaYr5GZL6BAgBQ7tGq9VE1gVUVSabLrCyeIpyKU8kiHTHNp36kLG5S7+9\ngaaEyHjk01lmZ2c5Ojqi1WgQAqHvIWsqlanSz42D5+tFU91jbAwYGz65fJlTq1c5KWmEsoSo+DS7\nbZqtKj98+48RsClPLzM5d55sJsvAOKLTOqDXHyKJCnpKZG5xCtM0majMcurM6/zk/b/i1MxFBLlA\nJrdIZeoUkZhhODZI5ZZIp6dIxCQUJU0iPkm7NcA0xySzGRJJHX/PJAhsBCFAlCwsu0+zeYSWjOHa\nATOzZ7m7cYCATjydJmrLeJ4EkY6uTlApzzMyTEbWiLm5ORQ5SadWQ5RGfPe7v8PI6HFi7hK//I1/\nhDO2ePJ0m1SxyH71MfsHO0jYhNEYQZAQ8KkfbODaIwQlycnVl6kfbqHlHSb1OcbDAoosIYppKkWV\ne48eIckKkeeR0CVWVm4gymki32B98yGf3vmQCxeW6Ip9TNtE6KtIQoIgdHDHPpX8JOl8HD9yGRpH\nbLY2qO7ECZCRtCwzs6vMTpfZ34JWa4flk7NIgsjuwR62bZMrF5jPrzC7MIMxHrB/tP9z4+C5BqFr\nuSS0JHEtxovXXyYIQiYmp/jg5kecv/ICjjcmk0tRmSixv3ufja27jFyRleXTHDVqmEYfQZAIo5BY\nLM7cQoW9nSoH1RorSwvMTJ9C1TIgxHnzzW8iSSKBqKPqAosnz6GJxzWcZbo0OsZxxWuO2TN2OXW6\niOfbBJGHIEYEkUUUHQNpkEXCIIJIJp5I47neZx58gQ+yJDNZmcM0x7h+RIAIQYAoqPiOQ6v7lH7v\nCYokMRo1UFQXURDo9OosrC4hKgs8uCfhuwERPgIRYWgj4NPttsmXE7ieSCqb4M7dT8nEKpTyM/ie\nQ74wSV6E9SdPyOQS7O1u0u/azC+dBDHCtgY8fnSHTCrGaDDAtLpoaoqh0SWb1uh0m5ycm6fb75HU\n04y9Mc1ai7FRQ5J9JFklUGSaxiN0SUMXA2bny1iuSbczwDDHxONx4qk4+UIOVVNp7beQlJ/fMXm+\nxunOAESF2alZNne2CQUX3zMox0Tu/+gHHO7uYRo+J+fOogs6WTVJUc+xtbZBpzkgcJLEE0VkNcWl\nq2+Syk6yvHqCtcd/xvfe/lPOX/wmcydXMEyTjz5a42jfwDUsbLOB63UZOjYNq0kvGhNIUGvUGZsD\ntCQ8ePIpI6uP55t4zhAv8gklg42tdYJQJJPLEbgR+YSG69aPqeeCRCgMSaZTvPDCy8iiDmHIT977\nE9rdQ7bqj9lpfMInn/4IKbIRsegNDGwUTGRSJYW3v/tn6GKRb/ziP+H02V8lEmfwAhlRAqQxnjUg\nNG1c0yUKRHJ5md3d+8gSxEtz3Lq7hjkyWT0xQ+9gE9XrMFOZQEXj0b13+f47v0euIDE5VSISQnQ1\nQxSIeK6BLLvE4zLxYppTF87gBj79dp2ziycoJSfJpqdJpfMsLpYpnhTJLzrHJprGATu1I5pGm1AR\nSOZTSDGJo94+99Y/xfE9HDv4uXHwXKdoPr7Z+W3TdIhJErXaIecunMOwRkSKiDMa8XRzi0qxQuTD\n4twKru8TS8n0hgZvfuVrrJw/RSY5xwvnrvMHv/d/ISISi2nkS0nur31Kf9xClZMEnocsQITLxsYP\nuffg37Cx9Tbra7fYWL9HjAr1wxq200eLh0zNneHi1TfY3VnDGPcJww54OWTRxzYN4nKOhJ5GSqSJ\nkDCNIZ1anfFYZXn5RV66/hUcL2BsmQz6fc6dvYiAjDUaMbM4x40bb9GqHzEe1gkDk8mpFWQhRSKZ\n4qMP/5JiZYrQS5COTxLTUgShh+NEFCaWWVi5SCjJSKKG6w55553fx/cNxqMBc4uniSk6g+6A5eXT\nTM6cwLAddC3L/l6NuK5Tzi2Tz0yhyyp720+IhOMtv3y+hCRHyFqA57vE4zGerD8ln80hCHkmZs4z\nN3+ZmZlLFIrnSMZSDAYeKDKCqqCmVTLZBPGMihe4uKFPGBzjxjwvIAhCfus3/8kXb5TrT/5087dL\n5TKiAOlkmlg8TiwW55N79ygXM+TzSUZGn/FohCxJdHsdOv0e8/MrzM6dotM2OTE/x+bG22xtf4fq\n0Q6377xPfyTw4ku/RLtpsru9zu7uNm+98RoPH9yi390iiPr4fkDgZvjP/+FvUMpVKBZVXL/O5vZH\n1Fs1Fk6cYnXpOi9e/gaBU2Q09Ll07ir1+iaRpeHakJuaIUSj1+px6fxlfvmb/xkrKy/g+iK7B7uM\nnQZBZKBpEu32JvcffhfHgwvnXuL6ta9y7/5H+H6PVmNINjOBpsU5qG4yM7VM6B9jaJOJNBOlGWL6\nSV579dewPZ3xOKDXqSHiUT14SBSMMccG8/OnAYG9vT02tp7QHw6JJVVKE2Vy+Qlc38b0bQbDBuNx\nC0kIWF55i4mJVRS5gOtIzM8vI0gi9VqbeCxDPJbkoLGH5Q1xgjERHoIgoYszpGKTyEoKTcugx3WM\ncYMwsnhm1PqM/AlEEIbRFzMI//Kv9n87Fo8TSBJGf0TtoEEykcYwLNqdQzy3T+ANEQSXRmuHsWFz\n7eo3OLV6js2tNQa9PufPTvGHf/A7iGGGidIyL734C+jpE3R6BoPBEYoIpUKe2dlJsmmNu49/iOsJ\n+G6Wf/Tr/xOyKtAd7PMX3/0dms37EBwROhaPHz6ilJtCVRVOri5y46VfwLXyNFoH6KqOKGpMTi6S\nylS4fPVFpmam0BIhvWGPnZ19xraJIqu4dkQ+M8GHH3yPINjB6PY4qvaYmbvB/Mlpbt9+F9u06XT6\nlCrTFLMn8RwFy20RRH1sa0hcLeCZIb2ecew4oQesr99h/dE6L127TKdRQ1OSZPJTyLLEwdEW+VIC\n0+zSH+7TG3VoD0zS5RyFyRKiLDEauqhCBSewEGQBx/WJxxP4QUAQxBBCHUKRdDpBvbWLKFuYZh1z\n1GI0aFGtb2OOujhmD9voMRo2kaWA0HcQAgkCGTgG64TBsXnmb/3mP/3izRMGQQ3bLxCXM2SzIYLQ\n58nGHiNjjBm2CSIFKRSI3D4CMl/+2j9E1XRkXSDwdU4tzTIyx2Ty88xNXuX1N68jMeRf/b//DDtI\nsrR8isV8ka2nm3x48z6Xz8+gKjLLKy9y4/qXCAKDv/ne73O4u0lG1xjbIq4SAxmyiTE/+sm/xLY9\nZFkAMc+XX/2veOnFX2VzfRffVTh97jzpXIVG7Sl/8Lv/gnZrBzvsc/Xat1g5/QaH+0eomkcqP8Wb\nb3yD2x+6dPwuh81b7G58gConWVq6wc7Bh3QGD+nUrxLPlEkkBfbuPsIxB5w5dZGNjbvkStC1fMLR\nCqoyx+XzV3A9i7WHu7xw9SvcuvPXHOx/wvzEl5GkHoqY49qF1/nr736HQN0ilc3TPTLpNdLkSpOs\nnFlmLlchijyM8ZCd6jbIHk/3dyGUyGaLyKKGPY5YmF8hFAz6nSOMsUnP6YOYxnB2IJIJgoBEMiKO\niChoz6ifPmEgEobRZ4Snn3eea2FyrJ8d9xi7gy67B7v0Bj2GoxGRn0a0FRJqnlR6lkRukWJlCS2W\nwxxZxFQZy+hxuL9HJpvh4pXzCNKAR08+YjhuMLZ6TE2XcByHRr1OPK7yl3/1x9hWm5eun8d1e3z/\ne3/Kwd5TFFVndfU8mpYk8EHTYsiSikCEIkcoakTkG1jjBvFknLmTS0zPL1LKTdPvdvnk1nscHm7i\neRa6qhD6ATFVw7YcIkQQZVbPXcB0QxKaiirBweE2ru8xt3CCUAgQFJftg0eMHRPH8+gPh4wsk64x\nwA8jJEGBEAaGQbPXQdF1JEVmZmaGdK5ENj9Ju3OIaXfxfY8wgnw+z+TUDGEIg36Xfr/DeDTCNk2I\nQlqtFo7nEIvHmJqqkErFmJzMUyikcL0RvughxFQsO+Bgv0Ymm+XE4hynziySLehE0TOMbGgxMluf\nufdHCM/otMeDrJ+HoYXnfBOORx6d4SOSKZ2RZbByZgWiCN8PcUyfcHiIG0mkynNMrZzGVzVkxWPj\n/m1GrS5SvsyPPvoxX//W32dr/wkf/5s/QJYdJEUkFs9wZmWJ/++f/TNMY8xrq7/A47U/h6DDv/g/\n/2dEIU4qkaFSUPDIMDl/llDRuHPvB+hSBsf0EHCRpOO/GgHvf/CvePn1/5SZxZc4sbDE2+/8OY8f\nPeDsmZP8+n/537GxeYs7d98j8EJyiTTGoIfrh5y7fBFH8Dh95U2e3P0rEnEJ06nhCotYTgJFnsFz\nR1i2RTqdYzQ+RE9JdNoj+vaACy++SHt/D99x8XEQFYv1vT32tx9wefUag1GEpFcwRp8SylVqtQOu\nXf0ykiozOTWN4ewzHHdJxEMKFZn1tXc53I2xvHgG6nEUWWL/aBs3GBKLy5w9d4FUvoThgmkFFJIn\nKRTLbD69ycjqYHhtsulp5mZOMRo5BFGXUDJxA4cIHyKRKBIQop/dgl/YIDStNvXuNmV3humpeTaf\nrhEEAhOVKTqdBnpC48tffR1JiPju97/N6XOvMjlR5vatvyYyPYZzp1ldOUd9v4sbRCSUWTQ9RC9q\n+IFMs7XN2NklEjQs0+XKpdf45KMOiqYRj8eRpAjLGTDyA9xApzR5jtzOAUoUEMomoW/ieg5hKBBF\nNqLW5ubHH3P63C/y8ScfUx/sk84JpHMFtNQC127MU55Z4uaH94mEiJg2Zm9nnY31EucuXePqS7/E\nzoP7uL6B7faRRQ81SrI6+wa+Z1KpLNDrrnPv3t8ihCahH9DrNlhaOUU8kUer7bJ9cETHblOsVLh2\n6Twf//gdTp5dxfEsMpkidx/8EEFMUiwVEGSXD2+/z5tvXeXH77xNTNHoD/bIZWxy2QSHrXUy8ZOk\n5CRxXScpqAhRwObmHqJWJVEosjB/mvnJE7SrR6RTGVx3yJOD+zTba+wcNBH8JKIakkgrhJGJJAn4\nwbFhtRQG/95t+PPO8/UnfLf12zPTE+RTWUb9PvKzIXDbMJicOMGpF9+iVMzx6Pb7bN//CVvbh5w9\ndwWjPSCfKaNn04ShCr5CTJYp5FIUS1lMd8RO9SEbW+/gWAaBF5LOLKNIOuORix4vYNkhrm/hh2Oc\nwCSVWsVzRWYmpilkcrQ6NRxvhChIhKGIH3p4uFy98iuMByLDoYGWmiaREnjnR98hW86Qyy0ST+WQ\nlDj5fBEparG5/ilqPIWmFUnECwhCSLvbJZmIYRsRrmkR1wTS8SRHR3s8evpH4LfR1ZAodBiP4KUb\nv4icyPPw7qdMFMpkU1mESOTB7R9TKSSoN6roMQnXtEilY5RKi5w5c571Jw/Y2n7CzOQcuhrHsh1q\nR23wBIRQxw+PF8xS6SSNowZSqCCJMUJJJoxgMOzRrDa4d/cB6+tPESOdMNSYml4mW+4wtNbR4j6q\n6iOKAgg+CBFRIBBFIhARRse+1WEE/8M//a0vXmHS6h6iiRp+5IMiEUgmouIhSrBX2+LMjRe48/F7\n3L19Cy+QWb2wyqBvc+7812jVtxnRo7a3xbjXI0RmanKO7maTQmWSUm6BnaMqYjTEl8bUa2tkc4sk\nCgtcungZ33HZePoBO7sfoYQirf0ay8tnUVSZ0vQ0jfYefruD4wwIwh5RAJFcZPXSi1j9APeoQafd\n5syl05T2In70Z/+a97Tv8q1f+3XiyRSdvkF56gJzy1WymSQn56fJFyqYvUWSiSSB79OodhBCn1Ae\nYismgT4+dv+SwHFtVCVGRESjtkEsMU8kyuTzGczhAKPeoFIoE8oj/Mig1zFQhQC8MtevfokfvfcO\nR9VdyvkSI0Pipde/yu/+3v+OQBc30ClPnqJYmKR6NKR/0GGiksHo28TTaVLlDJ3uEWlFQpYTNJsG\nSkpmYDUYOxK9gcLE3CWW5yW2dm4CPpGvIUghRCGSJBKFIT7HYMUoikD6+RyT51qYNLtNNvYeYzhd\nhnYPXwgIJBhaNsViBlnwONjfxbIdTp1+gbm504wsFyfy6JldDluHWM4IkQghCsiky7h+SK2xw+zM\nPApFhMBDJMC2RnhhSCyeoVHr4PqwsnKZqekL6OIJXBtkUUASJDwTiDRkQSEKPCQcEF1UOYssponp\nPvXGGp7fRVN1ioUySB0Cr8b7732XeEJhbNkQapw/fYPTpy6QTIncu3+L6n6NdruHZY5QVZGhOcSX\nQtzQ48TKMqEkEwXHH8zzXEQpoNmuEuIiKyFRZAMu3V4DYzygPFFEi2kIIsixGAEBzWaNZr1BPJYk\nmyngOB6e6x+3GgmQJI/1jU/Y2PyY3epdmu1N6o19LMemXJnCHJtUq4d0eh1kJWJmLsfcfJFyOYus\niTQ6Ne4+vIMkS8+26oTPBSh+oQuTVDpNpihjWQO8wKHdHZBK5Fk+f5Vg7JOIILIDrrzwOql0CtcL\n2DncR5NCaq0myBqWqfLatTcII418PsHT7ZsY9j5ja4Evvf73eHhrBscfk9CLJDSBWCyFORqys7vG\n9PQEc3MvsDSbIqbLtLp7DOpNem2Br/3CL/CHf/QEz9YREEGEuZkLiH6cJ2s/olm/hR4/Q1IrcHLh\nVR7e+jGaOKbTfMiPf6hx5swb9ASJTHaKTneH3/u3v0FMm+b08iqtVpV2d5+r114lkZ9mbXsbPX7M\n7kumzmH3HyCKIVEIghDy6d2blCfOMDc3hSoLBJ5MoNRQ4yr7hwFzU5cplqa58/hdKqVJGo0mcTmO\n5/nHM4TmiNHIYHp6DtsUGRo9BMGh0doiEjUQNAwzYvXUGdAkGltNyqVJBMmm0agBApWJRSanl5mR\nFWYXBzR6N3n89GMUWSE6Xif5Kc4TIoFIFAh97zPi0+fJNM81CBOxLMZoRH23ztlzZ5iZWOLoqMXC\n3Enu3v4xf/4n/5x6u8ZuTcSxTBQ1weVXv8X+zhG+4zFbLKDm83x87y5Xb7yFbcH1q1/i6d59Dna7\ndDsul669geP12Hm6y87DNRYWS+wdPSbA4s6dD0FIMrt0HVUoIIsSHjKpUgZPTvGPf+O3ada2+dM/\n+b9R6FAsVNDUiI1Hd5FlF3O8jWnvUCxMQhQDKSAWS7A0P40ajLAsm243IJkKcYJ1nN4QIVhBk0Uc\n12Z/v8GlC6vMewE7+3uUi3leuPAKH/3kCbJ0zAPxoxjp5CTGMCCmFzB7bQJHJpM8geUbuI5Frb1P\nb9Tm5OnrbD58zMnJeQp6kVAMGYwHtDs1trYFMpkcpWwRSQJj1KPfb2M6DqEvsjB3FkmNcdDYpVKp\n0O60iFyJixdf4snGHZqtOk+299FiCifPzOAxQFQ4xoUJHO/2AMfspvC4OhY5fgwKEQhf0CDcWF/D\n7rZZnF/EHcJYMRmMbAJRxB10aB7dB8GEQEaVU+iKxoOP/hrb1vn7v/brOKHHg/f/mrTmY4z7IKWI\nXJ3J5Cz5tMsoyrJ9+ATXM7DCIclciuULF3i4t0YQaUzMnmdxYYWhLeOYceJJhcZhg7mpLAfth8Tz\nN0iWX+C/+c3/jX/7R/8HmpihUX3ExPQk3b6P70S8/Rff4Tf+699EEiv4nk8+vUQpO43rOlT39ziq\nHjC2aySUVbL5BaIox+zMLAtLL1NvtXHDgBPzU6iix8bT2yzML0OYIR6bJl+YYmZuham5E0jKFJEH\nfUL6g30EIsrZRUIZNqv3STCC7jLnLrzC1vpdhNBkPOwgRC7lYoFyIYFlaqRSs8drDIMO8eQANdRQ\nVY3h0KDZaKJoIlJGY6JUodno8OjeOpZvkMknmEnpyEqM6madvtVG0iQCAiIRRERAgkggiKLj9p4o\nHN+QUUQk/vx0/VwREteu/4+R6Pi4poHlm0zMz3DUaPGVr3+Tm2//GbW9D5DUEMcXefGVr3Pv3iOG\nhsupUy9y/uLLDMYGnb1PaDX28GMVrl15HUXw+fbv/y8Imkwye418OofjGszOTHDu1AuMLOj1a0Sh\nhTXqYY9Nal2TU2dfo9mukc/JBJbDvYcfkMnPsLh4lgtnTx5v0zkyRwd7pLIe5niAIJWIKRWmpmYZ\njloE0RgiePJoHQkPJ4hIpHLIsoqmApKDKqZRZZEgNLl79yZ6XOHCpasocoq9nRbnzq/S7zsIgoai\nxkmkUkSiz2Ftm16rhefts7N3D2fUoVxeIZOfRtYluv021WqP1eXzOIZNXJPp99oMhlUyRRVVy1Es\nnSCRL6GpOhtrDxn0DtGFGJIoocXihMgoqs5kZQIEESIB0xkwtrq0Bw1GVh8EkWQqRywdEIotTKeO\nKEAQRM9yMp8J1VF43Lb7qYpd+3TriwfTESUZ07YQo4jQD7BNE9sywQ8QFRlJjhEELkEkMTIDYrEc\ntm0wPTWDJIqYQ4NsJsn+/oC+YRNEAAGiIuIGHouLSxjDEUrk02z16ZaHWB70Bm2EaETraJPmYQ0l\nPsPIGGDZFlpiEllPc+nsdbREikgQqLdaZOJZoiAknkiTTink89PYXpy4VsELRHKFKQQ5YNjvkM8X\nGXZq6DGdeEJHFpNIaoCsB/i2wcix2Nteo9/dJubEGI1X0RSNUnGSdqtFf6CSTGsgR9TqNaq1XVrt\nJxQyKXb3PsXz2kiyR7O9hR+FJNJZErrOZFFGkwMMxyETi6PKMfKFEp3BLlPTJbwQ2oMRqaTMzMIS\nnj1AEQIkGbSYSBDICILy7HcE33fQYgrICZTENK0eWPYY025h+QHxlHuMlI0CEAQi4afQ7fCYZScc\np+LPqVmA5xyEV669jDUYMRq2ePL0EUgq45GDZfuUJ+aJXAvX9egMTLZ2hpw/c4Vms0G5OMGob6CJ\nEo8f32dk1/ACmer+U8rlCSanrhzzd0cSo2GfYqHAoNtlbnaGgVHjhz/4c0zzCEkYIiEheiFi2GZ+\nJsto0KGUniMTX0bXPUJxjDEY0T/s4DgWxmCILi4hSBE7zXViaguECM8zSGeLtJuHaLKPi09cCbGs\nMfcf3Mfx27h+E1lUESURCRVJkkmlpnFHEW7UJZmEw6MGai7L3Uc30TQRUQjwPJeYbtNqVVHFYzeH\nCB8/HDE09hgMDonCCMEcMOjZXH/pq2yt3ccwhswtzJOvlFnfeEipEpEprCAQB0nl1PIV7n76NmpM\nojCRJQg0BCHN7lEDiEgmZEZOA0X1iCdjvPTqRRx3xO277+H5Dn7oPIO7R4RR+BlONuJYG5QA6XOk\nmZ+e5+uWWqV+AAAgAElEQVTAcNhGFUMEPcHUyRUgYkXL0OqOEOQUZ868jDE0qTgB9f6Ids/CcUMU\nWefTTz7CsUycYEgQjfBcj1u3/zXF/BIvnPsqt2++Tyyoko6piIGHLssEjklOUwnMPnE1xPZ9AhQ8\nf4/NJ+8TS2ToNHu8/ua3SGQm+fM//H9A6iJrOWaKq1RKGWyjxScfNhFQePlrX6aQm8N1TQZGnWar\nShR1Gbs26CoxOcvMVIm1hz9A1Q3MMeiJHMXiJGfOvkEytUC/6eCbbTr9fdaf3mF28iKEA/JZGBkd\nBr0BIIJqMV2ZottwUNEYOAaKHBKFFpIQISjisS3y9asYQY+d+n1USWBg5MlmTjI1PU+9dQ+jU0Uv\nLJMvzVNJS2RyZfzAYXd/D0XJcOb0PHMnT+N5DusbdxCUkMKERn/Y5t331lHUiFReotdrQKQc/28R\nIBxncICfIj3Fz59b+Ow8X7H68AGZfIbdgyMUWaVSqpDUVQ521pmZmOT7P/yQ5VOnsF2fiYkKw2ED\n067zvXe/TTqTx3EGLJ+8CvIVBgOT3rhOFMDYGrB04hyKqNEet9FTAfmJErduP+SVy2eRohihbyJL\n0vH+hj7JycV5atUmyUycO/ff49qVK7z8xip3bn+CNRhy+WunuP9wnSiWIJ1NcPrMOcqz09z5+Mcc\n7N2mXn+E7fi8+NLX6Y1T6HocYhlsdPKlUwwGXV564zVSuRUkQUCKQhzLpT88ZHNjnYmJIrqeY2o6\nxZPdT9hev40gDNESIYIwQ1KKY7sRi6sXcd0xjx/dRZQsBElEJEEYSMTTs5imzeON2yiKDXjUavfI\np/MUcwVMu8DIbmGNHuJILnriOgQxVFllbBrEYxobTzYIxU3y+SKvv/IV7j+4xfrdW8ydKDA7o2NY\nLbq9OiIgyN6xHBPKCMjHdXEUfqYZCpLwufrgT89zLUwuXPytaDBqMzN9gsAPMc0hoiSSSsaRI4+9\nzQaXrr6MEkvQGdTZP7jPyKjhOh4vX3+Rnb1HHBw0KRZPc3b1DbrdOn7gIQgB27v7LCysMB43GIwb\nfP0b/4AHt7Z48eJFHqx9hOX0qB7tYNo+J06eQY3gYHeH+RPT7Na3aLf6vPHqNykWJvjB97/HL/7K\nt/jo449xvYCXX3mNdCrOd//0n9PpbOM5dWQ5IqDAtRt/D8stM1FawLVGxBQFwQkwxlWG3gG9QYeR\nMcYwRjiWy6uvfZ1MZgXPddjf3aJSzmB7PbY379Pv7yBIDRQpQ1wro8QXOTF/AVVWiOkCH378Q1Lp\nGMX8FLKkI/g+j5/eQ497iJKJ71s4toUk5Th3+utIchqbQ9YfP+HG9TcYdjz0eJy9/S30VEgkBoiS\nSkJXCUIRc3TchiOQaLU7RKqDllCYmc9T7d4kDE1C3GOYoighCCJBEHy2bwMQhiHCszS9/8HT/2Bu\nfs7WcBK5bAFNURkMuvi+Q4RLp1ejVttHkkSSyQyW7eCHHsmkjm2PEIUI3ws4c/oigiTT6VR5/PQj\nHCtCFlRanSOC0EKPqYxHPcajPo41YnfnCWN7QBRK6HqB1dUbXDj/GvMzS9SPmsT0BLKi4TkBsqpz\n584ajYbBqTNXaHQMkHQ0PU4YhhwdHjDsHSAKA0TRwQ9cwgB8FzQ1DpGMbRuo2nEL69HD+6yv3WJ3\n913anbt4bodsNo3nBKiqRiZTQNeTHFQPcTyBXHGOWKpMgIRAgCApuE7E2AyQ5TSjsc/q6gtMTS6T\nz08jq0lMx0eIBFzbRUBFkRMoik4QetTrLRxbQhSSrK6eJx5PcFSromk6iqIT05McVg9JJBQQQyQp\nQtNlMpkkshqRzsbxfJ/RaEin1yYWSxMiIkgiiMJnZHdJkn7WPRGOtU5BFBA+R6J5rul4YWEJTZFo\nNuqsLJ2k2drHcobE4yGGq3Lt5bcYuD6+IhFYEfWjOq4dMrcwj9FPgD/Pa9dPMrKGeAGM+x2Mbhsh\naqNGDovFPAmxzCf3N/nh3/4+nm3wh3/8gExqllSmQiJRRhBFHmx/hCpH9AdDlrKXuPHqMpqsECAi\nSjEIk1SP9kjGCshiQK/R4uhwGxHleDE9KKEpExSKy6Rii6ipKSzTxDAc0kkfSXCYrBSxvIhi5cuk\nUlkQ0/iuhqTIVHe3kUQdIQDLGGBFAaurl9FSWR5+eoiqaGRzM5w+9xa+pxD6PrubWyBEOLZDPNEl\nm8sSr5RYTV9g0Gsxsh10LcHcQg5RlkjGy6hahngyRa/T4MMPP6CQKaNqGpXKJAEup0+/wEF1l7n5\nBaYmZ+l2usgKqKmQqUSeipVkv7bFmCqRZT27OZ+N8IfPUrDwsxQcRCGSJP1HU/LznaxGJJB00GP4\ngY8YeChhSLvVplK5zMiNCKMxpmNSPaqRihdJamly6Qm2Np+QybTREwIDy0KPlZHiEZoi47Q8Sgno\ndm4jifDai6/SaFtsuWu4jk+zc8hwNKBQGJHMFBAEnzA0EbQIX/QZd5rYTp+DepX5uQsk5CVsM8Bz\noJzPEzgeuUyRupxkauIS3a7F2YtnUTX9eEhUHrNZ/ZQwDDFtFdmLMEcO8zOXISkRRSAzoNreoNXp\nMJW/gKZkkAWRdDJBoz+g2+kwM7vE1loB167hu0Mer31CPjfNyBjheAOyuSQT5TkODquMxz18USYd\nK2B6TSZnlhEFjTAERZZwA5NW7Yhuo4FtG2SyOWzLOoYz+mPGYwNJkliaW6XaqHOw3+Pai69guT0O\nD9eIuxKV6TzTWpq9wwPCyAUiQsRn7TqOK/S/cwset/M+Pw6eaxDu7G2QyZU4sbTI2t2bGK0uoiAw\nP3uGQC0QyyTYuP0BnUGXxdVL+COP+tER5fJJ2g0Xd+RhWw7Z8iTliRW2j6rYhktKimN5j/nJpzeZ\nmXiTE4svENcqLC1lESUfRQDbseiPHbqmTSabwulCOp1GCAI+fv93CUSDfPkCcSUAb59hp4rrCBTy\nCbREHNX1iQIVx5W4eu0GH9/5gHZ/BxB55ZW38N0GR40ukiySTxTRc3FQZG7e+guscRtZHBx/O7nE\n7KWvELgqg56Fa7kIrkUhE6PXahD4IqIIR/V7eME+6up1krEU+8MOpXIMx3colsrHQjgBrWaHiAhN\nUUnGs3S6feqHNUQCVFkkncxSyGfodDtcOHeGtSePkSSBhcUFDvb3cNWQlZMn6A0smq0jdmp3Kc76\ndPqHdJ4c72ArkoAXCUTR8S6xIAjPNEGO0++z7xs9a+UJwue/+p5rEE5P5VBEiVsfvIsiC5Rm5lBl\nnWHfZuH8AmDSbW1TKOepVvfIZ2Z48eU3qe4eMj1/kuGwQxiFuL7Awe4hdnBAeSLJ7pNdLKsJUsj6\n7qds7OxSzp7mxMIUT558gigeC6vp8jzZygT2sI7rqUxV5jkxu8It2ccKXIqJeeQggevWGHTWKE2c\nwHY7yEEeVVPR5CLgcFTf5vTqGdxwmn7PYGfzkJXl00RhndCRaTkd4imJvmfy+mtfYfPpx1R33yeI\nNHxPxA0DwKXXO8L3x5TKeca9HrlSEVUtgC+gYiNKMeYmlxh2huSzOfb2n3Lh4jSHtQH7h9uU0ini\neg5dkziqHiBLA/K5Cql4DlmM8H0bWZWJJ3QSyQzDUY/QcQiBXruLKAXUOltEMYVkOkMomaRLFs3+\n1mccFVEU8f3os2pCEJ5N0Aj8bLz/Wfr9vHfgv3uea2ESeDbbWxsk4wrpbIL+yMC0XSRJRwx8XMdi\nZnaGcrGC50UsLJ5gbI0w3SFaQsYLXLS4hmH0kRWfU6fziHIXw26DoBEFCSTZRRBsYgmFdr+Ooguo\nmkg6k0QURaYqk6iKjuOOcX2TIIR8bgZZyBAFx4s+1eoRggDpVArbHCNFERICYSiRTObY3d2l229i\nmWNkUaaQK9JpDyhmsgiBj2ubeJ5NAOjqBCtLNxClSQRKaGoRx/ZxXJcgtCC0iSL/mAxqWkyU5sjl\nFzhz7k1WTl1jMHCwbQFdi+M4Dp7vMbe4RHliBhERz3Wp16p43hhB9HF9i3hSR9FFipUi5Yki5coE\niAp71Sq6nkAQNYyRTTKTwo0chkYLyxsyGPWwXQtRihDE6JkkGIL40xtO+GxM698d5fosCIWfvRM/\nb9Trud6E3W4NAgdNBlmB7qiLFktRKZbxxl0CLFxX4qjhcPXGlxAFn3bjiP3GI4Z2FVlK0qwecfbM\nCvGYzI/ef4eh0URUbPzARQxUZDdBMlkhm56mPWwfg6YXFskmC2xudlGdKQqxBnvGx+xWB1x6+SIX\nX/g6f/ODbyPHI0J1TCj5XLj8MoOBh2f6BCObUJMpFsrE1AnmZkXur7+NII6IqVnSqQmGgxFT+Tni\nWgZF8zCtESND48TCOWRSfPlL/z0BFu3egN7AQxJ8LKeNIhn4YZx+r00QSOTzM8j6EqOxgRMNqVU3\nmanMoPg6mVSWew8ecv2VE7z11W/x+L13GI1MCvkEg8ERbugSxUXCSOLpk8doqoyISCZVoViYYGXl\nPJoYJxJkJFXGpAGjbfr2PuN6l9mFUyTEIq7VQRDdZ+24iEgIkAQV+PcDTohEBEH4mSVKeKwZ/se2\n7Z5rEGYyE6TSQxxjRPXBHqqSI6kWUItl+of7RKJLamKVk+Up8AUePnpALC0ghxGxMESTXSI9SyqV\n5G/+4n8lUmwkFCRfQpBFRDFBLLXA/OxZrLGNZw9YOXMGSU7hoJKbnOCouYVpbuGrNZzhkE6tS2Hq\nBLJaYTDsk04XOX/xlwj8MY3WBo4/ptYIji3q8hUkOSDoW5w5eZ764R5js4ug90mqMrbdw7L6yLEs\nkZInky+wvrbFicUJwkh9Zr+xy872OqXSJHbo4Ok2mULAeGyiyDIHR3cQohS5rEKrto8kabiugSBF\nRAFkNZ8nN9/BqZ8imU2zfbBGpbTI1HSAFos4ardZefGXietzNKqP6HT3sQOPUNe5+fARc+USkqgQ\nIFGYTFEuztGzP8S3DZ48spiYWCQrX6Zv30eQDAQURGSiz+qP49swiKJnHZPos0JEEqVjnVAQkKQv\nqHt/qFrUD7vkYmmWVk5jjEMajRrpiUkyxTydVh0VgYe3PsXzQi5de4EPP3mPpZOn8c0Rg8GQdH4W\nUUijSkUsqYMoxNG09HFv002zMHOVKFAoFTPkCiq7209ZWblAFECndUAiqbJ/8Cmi4IIMb//g9/jW\nr/xjlk+8wZWrLxwLrZHM3/7V7zAxWSLyQ2BIq9VEJELTc3ihShjlKE0WSNlDvMBB02VymRwRAl6k\nIqhZJqZOQODh4lIqTRA4EoIUMui3ESSDvrGGbCmoqRkkOYZhjsnm0zSqbQRUEskkrhPg+w6qUCQV\nc0HuMRhWWdvaRdHK6PGIRFKh0aoxPuyRzEzw8O5NVpdXMJMZpksvsrtfo759xFuvfIWd7e8zGPYZ\nDCxOLL5FKjbDRPIX2dl/jJnost99iOuJlKeEY75fJB5XwtHx7fbTVBtF0c8tgiVJ+uIOtT5cu8Pq\n0kWa1TZKPoZpjcjmcgROB8vxScZ0GgeHhIHN5NQUH9/6hHNnLxM4LTZ272G7faRUnEjMgOQgCVmK\n5XkqxUXSmTRGV8G3wPcDum4H06mjKQIP7n6C78HsfJl68wGKYhG6EqHoIYht3v3R3/LWG7+KJAXo\nmsx3/uBfktI0BEQczyOSbEZOHzUCRY0hSTHymQIQoqgxZFkmjAJEKcK0bAqFEparkolnGQz3kOWA\n8biB0YVuu4o1btEd7iKKA6IwidHtMzmzjKTGEaUh6VQCx7TJ58qkEgqe5+ErLRy3Tz5VJKFP4rke\nrcEhoeCgqOA4BqIUIuIyX06zt7WG53tEgYhv2+QKcW5+8iHT5Smy6QJC2OW9dx5wcuECqcUY5y9c\n5b373yZWSJAhjU+PkOi4O8LPAurzNMCfvhX/7pvx757nGoRLiyeZKBXJxLOYwzHpjI4k+RzVttDF\nOKEvYJh9BEI2t9coTSwSBB5B6OL5FpIUYJpDHMcmCiNEdPrtMUZ3h+npGWLKFJJ0/CZxfZcwDFHk\nECEISOpxYlrEyDhClEUCT0YQfSQpwnNdvMBBkpJs7+wgEpAvTuD4AV6kIEoiSiKB0x+juiam3WJs\nSSiyTCE/iSLKDEZjBsMeCCDLOrpWJHDGbD99jGm1CDwPTSozUdEZjRoEnokggSAEBK6JrmuktSy1\ngya6qBJKApqSJpFM4nk2g+E+gijhOQKqqqFrCRKJMWOrSRj4eIGJIEboqkyneYQsaTgEeLiocQGf\nMZlihla/j6pAqqBiOWM6vQPi03k2n1YJI9BkCAObSAyJQhEQQBT+g4PSfzfMfpqCv9BvwmwyQ6fZ\noFCq4No+tfoBhjFC1DQq6Ql6Q5tsLoPvWUzOTDI0LGQ54unTLZwwRJXS2KbCaCAyP3cFWU0Qj+cQ\nQhGEkFa9QxgJxOIJ9FgMJxBotRqcWDjNoG9w5/YHTM9qNJsWEglkOUQSYrz62leIxbJ89OFd4prK\n1YtvUOu3EEWZVD5O3z7CCm3yxWlCf4wftDA6LQRBoNXaIB2vEAQiqqogKyoxDUyzw8Zan17zAC8c\nkIprzFYknmz9/+2dWW9kR5bffxFx95sr9yJZe5VK6pbUrR7PePph0PYAjQH8aPir+IsZMAwD44EN\nD2Y0aslSt5badxbXTOZ691j8kGSpVFp6DBigHvIHEASTly+8f5yIc84/TvxvUNPFjU4mIIiAJuPx\nN19x+dpteukK1XhEp9Ph5HhKu7PB5uYmdSXpthVHxy+ZzQ/OPIErZ2ep5yhlAcfWep+jlxPG04rO\nxjo1BcKfE7YSqkChuiOczMnkAcm2YT58ypPHG0SrCj+IkcbiRImQDoU6G4EnvvUIvqE8ceamOXfR\nGLsYB/dmL/mHuFADw3/4T//ZeSKhmI356ps/UBRz4rjD+7/4a0anFTIIaYqM2XjAdDbl2vU7zKZz\nrKdI2l0Cr42wIYGniKOGyXyC7wnqqiCfVphKcOfO+xydTFCJZDy7y6NHn3HnnX/LzqUbPHt6n3L2\nmOFpTbvdJW31uLTxLr3+Dp//6TPa7Zg0SclmFpFMGJxOuXLlQx6//ITp+IDdtXfodhOm2T7WzfCF\no8wzTk/HXNm5Q+DFZHmOFT5B1CUKO3jKYRpHNpki5YTB6QMsGc4tlq0wBMUqjjXiuM80myL9indu\n/4q6jhAyYWd3F19GvHr1gsCrePHiHkWesb15i6IaUzcj/NDhqDkdTmklW1gtSdotpBextdbm/tP7\nXHvvXXrbgud7d5lXjxDCIFyKcwKEwakaJ+Rrn+A550vr2xHu/HNjzmYRKvmdz5/+tz/9/JzVabzF\n44f3mc32cGh+/3d/R6e9xhefPcXolFtXL/PJv/wjzjRsXNpkPD3B1RLbBITdFk0lGE/uE4UGjOB4\n8BJtDLvbt+h0N+n3NjkezamFRrqS/cNnKGFIkjbzwhG2brC9fYNkMkZXFoViXtUMHn2KshMGJyPm\naYuVjXVskTE9eYhZbVOPH5Iog3QV82nO6WgfrcfgKjwvoNGOrM7x4zatbsrjRx9jbUgU3aAT7xLF\nKagufism1DOq+QApPaRQNE1DZ62PICbPx/h+jgpqHj/8kg8+/B293mXCMKXfX+GLLz7jys4Gl9Zv\nUFQZ83zK9qUtnr/MaBpLEMTcvHGNg4MBYRoivJpKzxiPU25e+S33Hn7BrfAmt2/8DZ9/OQd/jKVC\neA0OixECJRJez3c748193g/VBF/3i6X8s0sxXLAIP/mXL5AyI4gUv/vbvwUiilIBPW69c5PPP/lf\nbKx3qZua0XxEoCS61DgUs6ljfXMNhMSakjyb0O14eF4bAVza2eCbew9Iozatrs+rg/tIXRIHHYIg\nIk0iHtz7hBflS6ySrPevo/yARy8e0OkFSL/F7evvojx4dXSffDTl8uVVHt37HN9b9KhDofB8RYjC\nOocSAYHfJ1zp4WSbUsTUZcFK/z067T67Nz+g39+lKQ2np0OOh4/wvJiwu4W1hjhqEYV9qkbjeYpW\nC/LsgFk2xVJz/96n/Pt/dxUvEHieRqmGBw/vs7m2ThJ3qXTFq8Njdi7fJPB8irLk0tY2tQ4ZTxbn\nag5PHpIFQ2703mNzV3PvyT/z5YOGldUIi0R6i/QDKRfWfeEWbTdnv5eEvJ1svF2ctny7FP9sExPn\nDDdvXKazkoLw8VQbSRujp3z19Z9QqmE4HKCtIe53KWZzlLRIUXN08IB5PmRn430msynzySlNPUXr\nKdu7fT7/02c0usJzGaPxiNH4OaH1kMkqOIHnGVrRmHn5iMjdYqu1ytbWNtl4HysLGmMYDI84Pn5B\nVT4ial1GFjUffPAbjg9fAZZsVqAUOO0ReW3KqqYVXyJKtzGej4sC6toj8ftgQ14dDvjy4X2iIGE+\nHFNXxyShRTsLwhFLQbvTJ2xi5rMRKlTk2d7i0kI5Z57t8/f/479w7dq7/OYv/4KV9TbOVVRVjrGa\n3cvbDIYjTkcZAFpr6uaQTrvL0eAZ7SRid/sXHL56yvO9P3Lrw3eYyj1AYMwUKfTZHi9C4BbGDjib\nsfX2u/tuBPwppJQ/uS+8WCvXlT79fh+UxvMj8rllPh3Q2Iqt9S5Pnz2jsQXtToqxmqi1QiJTTg+P\nCJAoF5DpCSQNMjf4tUeSxASR4HQyJfACumsp84MDhKzQVpOGAcaCVCHK6yLkGiLoE4W71I0giSNy\nXVGWDtX2CaMGUxc4ZkymjmE6YX3rfQSKwWBvkf1aR9rZpTh8SVlolJfjvIROskFTlJTZE8qxwYwK\nKuNwYYIuK1qJh6cERZbTGE2mfCRHTOaWMIxRXkKru8XgpEB5DcKfUugjDo4jnj/bYnAyYDYfUGYF\n/V6Pq8lVOtrR6AbDGClraj1F+Rs4GzMdQRwlrPZvMq+GHO+X9DeuM5ocIsQp2BqsD36z8OrbRU3Q\nnLmlHQtBnS+wPyasc4GedfcQ1uHcj8+svlARrq72cdYHE5PPLY8fP6Asa9bX1/H9FkIFXL3yDrPZ\nhGaeI0VFd/My3c4GQgHKYh0YXZGuXmbWhf7qCmVdIhiCriiqGTdvXufTTx/TUNL2HA8ePUbIFF9t\n0e+oxRAga3jxYp8wjJjXE7oru7T7axwM7uJkQOw5hDHs7z2g6hl6nRWC0OJHMWl3hyTtcP3KBzx9\n9hXa5eQjyS/e22I8eMbR8RO6QZt2N0JpR1Uv3DVh1FkMmGwnZHnFZFIQ+B6X+jtY3WCrmsRLuH3l\nDkeTfeblEOvg5OQlk+kNfN+hpCOOfOazGU8fP2Q0GfD73/9HPv7sH7BejvEFp1PDO7fvELc0D5+8\nJFAtAtfj5bMJ27rP1soaw/xrbDDEiAbJwiHtkGfGhO/3fv81PkEp5bfP/MSjFypCPEndQDXXhJHP\ntWu71E3Og0dfc2Pnr/jwo4/YP3iGkBGeahBO8OzpC7rdDWQgcUIjrUUYTZ41JNdukDvL0eCYVquF\nneccvSqYjQ3vv/97vvnmS6yoiFPB85dfcPvyLQ6eHVJVNfcffULd1GzvdsnyGZtXNqh1Q5S00W6d\nOIiRrqLUsNpPmM2GzIoRMlAo1ULIgEB1uXbjNvNyzN2vTlC2gWbOpY0eognIq5xASjzZ0FhN42Kq\nSuNMxcrqJh/s/IK6TilcjBI1gQ/D05ccT+d0kl3CaIWimNJJJScnjzk6PCAKAuKwixaWwfEelZ3x\n6af/k8C3hKlmf3Sf966vc/feP5D2MsqzI5wePX77u494dveQu18+Zed2h5keIIIaXICUCmMXGbCS\nC8GdC+88KXm7L/xjS/ObCcwPyuD/t67+X1C+wPMVnX6L6WRMVVXce3Cf27feodOKOR3vM5mNqaua\n9dUtsmnNymoHU9bEYbgYO2YrnBQUOK531pjNp9y6cptECYrRKU9f3WU0MRg0N+98RL+V8uTFc5xz\n3H/0BarJCcIOXjLD5B5SrGL0nFBVVI1GWVjpXMVLE2LToDtwPJriKZ92u0NWD5nNM4x1PH7yFb94\n/zc0usU7t2L++OnHzOanVPmYdrKB56WkoaSszjJI4bO6vsnzZ99QHx9RW8XW5ju0Unj+4j6DwSHC\nQBx0sIGPcF3acYiQNfsnzwiCRTE49DzQhv5Km+ev9jgd7dHrd3CFI4lSHh78M/5WQRPkOOPQbg52\nypOjMfFuj60Nw6waoAKJkCHCCuyZ0KRY2PNx35ZevhPhzvihaLmYQ/PnjVoXHAk9HJLZvKAoch4+\necD7v/wVSbxCFCX80xf/nctXNjCVj/JC1jqXOD0Y0VvtUhdzJqdDLAVCWda6Kxw9v0+W5QxOhqyt\nrVPmM6SY02kp5tlj2pXk+aAilH2EssyKEZ12h5Wuz94ehH4LJypgxtGL56xvrC3udFu9ga0D6sbg\n+Qqn5jRovCBA4VFPRkQ6YKUXs//yPr64QxgZcA2tqE83hnye00rW0KJGxWDtnEYHeMklRPgQa3Oo\ncl48/AOxr6jKMWFTomSLxGtRVhnS+TjPIYWjE3Qo6xwv8shtTWulTy1Lbv/yKvuvTlnb/IAgDLj7\n/FOiFag8S218QqtAWBoKhCwZ10eLdxFKHApnPXCLU3NKKTyxsO8LALEwrC4E+H3BnYvubVvXn7Ny\nXaif0DqH73tk0xkPHz7i3/z6I3rdHoHv8+nnn5N2UyqdkVdTZtkEhCWKI/zARxuNRhMlIdo06KYg\ny0+YzY7Z3OwQx4IgEuAkSiqiMCKfF4yHA8piynwyxFPu9T0b2IA06aGUh0PjeQ3Hxy+AhsbUrK9t\nkCYtpHB4nsVSgZQ45xGFCdaUTMZDAg8CT5EXGX4g6PU7bGxs4gcewkmCKEaKRU2wyGvCqI3nhUjp\n00o6xHGMUGDRSF8iAoERFucq6jqjqopFOYgAjwCQ1LrG0KCdwEmf2llQMb2VS7SSDgoF1i1G6AEg\nFq5nYRDYRSbMt7VAx3fd0GfD317LTnyvQbfgx5bcP9c7vlAR6iZnMHjJ/qtH/M1f/yWhp/Cc5eN/\n/AMILy0AAAoGSURBVHtafZ92PyVrMmoKinLAwwf/B8eco5PnqKgh7UmmeUGYdAnTiOn0CKFyosRS\n6zGOkiDq0NQB0vWo84hu6ihne2SzfaQwi8n8/goqarG2uUNRSpyL2T96wGg0II5WSJM+ZVZR5SV1\nlZPPR5imoLdyCV9u0Y7XgDlK5uTZCOUPafSALDvm+OQR+8M9ZOhTlQVOSyK/TSh7KCLSoEs72sE1\nLUwdAy1yY1jZvoQNfIzyCFoJRT2grIfUTU5VVVgC0tYqoZ8wn5yS56f4oSLHsHp1iwev7vJs7zmy\naXFz95dELiBREqEMFo2QIKR6XT55c9k8j2Zvj/r9KSGd+wjffObNZftnuyfEGNppwq8/uoM2JVob\nnNB8+OvbjMop47LBVRJTQzMvMKUhDEpO9SuKqWN1dYe1aIPATwmTEl/NSJIW+UwAIb4nUZ4h8D2y\naQbCI0k0x4MJfpAsosX6dfYPT7n57m10bagquLL9V/Q6G2BDyrJknk0Znz6h1YoIlSJ3i3s60tYG\nY29Mk+Uow+LsrwnYP/wClMVjMfLDT/oU84IqmyJ8gZdEKBHSihOqvGSjf4mVVoptJFUxJ4wSOt0u\np+MJ2khanR5KCo4ODjAGnCfxo4iybgBFt92lynKSjmBrt8Pe8AnpmuRockg1D6gfS4I0RQuN8QqE\ncYulVUqsMWdjBb9bDZRn3Y63RfTm8vpmhPuxJfc7HZQf4UIjoRIREo/alTSyocYwLWfkeo5oJti8\nQVYxskhppo6/+NVHjEb71OaIygyY5TlSdWil2zx5dkAUBzRNTlnN8X1Bp5MiVYLWHkEQsbu9wsv9\nPawMkUGHuL9L0r+O8wOC1GMyH+KExemEbF4xGh8ynh6RVY9ptWE8OSaOEtb6l+i0t9i9fJvKHqDN\nKZHfJQ03iIN1otAgxAyMj6c61DYAFaCUYzodcnj4Eomj200Zj4/J5otIllcjoraAxpB4IVe2dxf3\nuDSwvnqNIIiQanGoKEwESWsh5pXuFrFqc/qipMokRjcIxgTtIb0rNYP5AfOyweAjlEX44ARYIb8z\nrOiHIiJ8K7Dz35//fC46dzal//zrHPuGs/pn2zFRTiCMwClFrQtqW1Prhso2mEYjqSjyOU2tWL+0\nwXSmcXKGCg4xtsu4fETYuoKNxnhuRtkUOAdRFHI8eEWrbOEIubS1g9Yh3zx8iEokwviknS7d9ioK\nSTeOGO0NKMcnlOWISkncTCKVATRhpLBKo+KGeTUizyR14zGfjqnrEqk8wnCVqHuZRs+w2QqBbqGJ\nUYSIysPWEEUBShZYG5LVkNqcujiiYo5DoXyF1AHzouDVwRAlJcKGDI5G3PnVbylMyenhIWnUQpDQ\nuIz2RkzgfJSMqEan7H09Y/X2VU7Fs8XdzuaU3o7C2vrMUBDhnEUqgbXmtckA6/CEWFwFJrzXkctT\nEmP1YgDreRH6LEp+py8sFkePpZSvI6p0301QfoyLTUzEYqCi0ed3XVisNTS6orElKEulC5yw7Ozu\nUpQz8mL67WRQp2inHY4ODha+QdfghwInDI3TSN/D8wLq2jAejVld72GNI0lbxFGEsJbjowM67ZTB\n4JiyKFC+wuFod5PFkEcngABtSgAarVFKkiYx+y9f4LTCkeJHK1griKIWyosJwhS7sAGc3eJuEVJh\nrUAqtXhpVOTliEZnaJNRNwVCSHwvYjbNmU4LJD7GWKyG1ZUttBHEcYvVjR5GNpTMsFGO6tQknZBG\n+0jXwhmBNef/V41SGmPL7y2hsLiI7s1kQwiHEO6sffzDUezNaPhmVPzXtPHe5mLnE/oSLJTaLISj\nK4ypaJqMxs6o6pK0G+NsRG9tlUdPP8f5BVKFeL5CmAhlG3QxRUqHH0C3l3A4OCHuB7jIIArHeDTB\n8xLW17vgVUBMErfRTcHp0YBgu42zDc4akBLhOazUaOvw/ATH4jpZIXxA0O0mpK0O0s7Y3rhJXgjS\n3lVC3zHNRjjZpdONyJpXaKuRtSMJY3RjEcIRJa3FoXFZM8sGxC2JUh7zab3ItAmQykNKjyAM0Nrx\nyccf85tff4AQHkfDE9audfCqnFyMqZVBOli/fgfvKKYuNX7g4YTBOQ3CYDEIBc7537FiCXmWF1uH\nVBKrFyfrxJmF31n3+ujmm86Zt2uAi6KN+95z599/tr1js/BZ4JyjbhqquqDWJWU1o9YVBotVPu++\n9yv++NUf0Wof5VVgO6A0Qs159fJLdjc3uHd/wp07v6TT73AymdNejxDSIp1bTE5Y3+H5s4cI39A0\nOa4JiPwIj4rh8QQlLSJQNBiStI3VFukHOARJK0XmHep6IaLT6XMGE0OarhP6qzS1BFeSVwWD4Ql+\nFBL1e6jJMZ512MziC58KicNbdFf8COk0SbQCNgdhcbahKUu8tEe3s4o1kLYihsMjwrjm62/+wKw6\nYWOjxz99+l/ZuNHDygk1GgGc1Hdpb2yyt/ectZ2AxlmsdIDE2rOIJb8Vked5i1mHloVb+syset7n\ndWcFQufk9/aAP1R2eVug8g3x/hQXOxDJ1WAbjNXUdUnTlNRNQd1UNNpgHfT7XYbDQ2blPiowSF/g\nhQLP9/E9zep6wuHxPkEcsb51lfuPn9BZDxGBwY8TOqtduqs9jgYn9PtrOO3jS4+6LkhjRYilLmdM\np2OquqbV6oILaLX6WOtwAtJ2G2N9wEcpgZQFnl+Sl8dkxRG9rkeRnzCfD/E8g5Aa3/NJwhSfAA8P\nrTWm1gRRSq+3SittY43HxtZ1PNXF2BCloK5zfD+krhschqwe0t1RFPaAoh5i7YRJ9oLd6ymaAULo\nxcgN4dDilLm9R2ezROvi9XAiKRRKBkgVIKVESfn6dwKBEPJsL+cWq9OiMAhndixxNgiTN2qJf/bV\nOoe2ZuGuFj/9Vxd7+N1kGJNjTEljSrJyTtkUWBqEqBCiYHD6hKPBXeJ2hh/GeEGADEt81SPiKrNc\nM7cZq1u7PNv/iqx6RZyUNGVJLDfw1DZBtE53pYOTi7tA2t0end4qRamRSlNXpwsnTyDwhI9yktHo\nBGMaprM53d4WyJC01cUYQeC38EREoCSBB5PxMUJYIi8EkWHdiNBP8b2UvMrQ4QTtTc5GZURoI0mT\nNo22+FFEnPSRMkF5At+TYEJ8FeEpCXHJyLzAhDOCyMOYxR5aeAIrqoWAEEg0SoD2NDY0CP+NPZ4E\n5TmktMizLFdJiRQCJXyUUGf+P4txGifcopgtF5Mvz0vYztmzPeJPF59fZ8RSLnyJUuJ+Yqt4ofb+\nJUvgopfjJUtYinDJz4ClCJdcOEsRLrlwliJccuEsRbjkwlmKcMmFsxThkgtnKcIlF85ShEsunKUI\nl1w4SxEuuXCWIlxy4SxFuOTCWYpwyYWzFOGSC2cpwiUXzlKESy6cpQiXXDhLES65cJYiXHLhLEW4\n5MJZinDJhfN/Ae7pwenVO2wQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9955b8e320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAADGCAYAAADoikhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFWdJREFUeJzt3X2UXXV56PHvkBGQOrFBxvJSFbXp\nI2i1BOUmQgwvFr0qWjW+oUuD2FZLLVbrvVirBV3Ktd405c16uYC03FZdosaXogQREBpfIHhv6yo+\nKDQqJpVBUxLFCknm/vHbQ04Oc86cyczh/Dx8P2vNmnP22b+9n/PsvX/P3r+9MxmZnJxEkiTVY69B\nByBJknZncZYkqTIWZ0mSKmNxliSpMhZnSZIqY3GWJKkyo73MFBFPAT4DrMnM89s+ezbwfmAHcEVm\nvreZvgZYCkwCp2fmjfMZuCRJw2rG4hwRvwKcB1zdYZZzgecAPwSui4hPAuPA4sxcFhGHAZcAy+Yn\nZEmShlsvw9q/AJ4HbGr/ICKeAPwkM3+QmTuBK4ATmp+1AJl5C7AoIhbOW9SSJA2xGYtzZm7PzJ93\n+PhAYKLl/Z3AQdNMn2imSZKkGfR0z3kWRmY5/X7bt++YHB1dMM/hSJJUrY61ca7FeRO7XxEf0ky7\nt236wcDmbgvasuWeOYZSj/HxMSYmtg06jKFjXvvDvPaHee2PYcrr+PhYx8/m9E+pMnMjsDAiDo2I\nUeAFwLrmZyVARCwBNmXmcGRTkqQ+6+Vp7SOB1cChwH0RsRL4LPBvmflp4E3AR5vZP56ZtwK3RsSG\niFgP7ARO60fwkiQNo5Fa/svIiYltdQQyD4Zp2KUm5rU/zGt/mNf+GKa8jo+Pdbzn7F8IkySpMhZn\nSZIqY3GWJKkyFmdJkipjcZYkqTIWZ0mSKmNxliSpMhZnSZIqY3GWJKkyFmdJkipjcZYkqTIWZ0mS\nKmNxliSpMhZnSZIqY3GWJKkyFmdJkipjcZYkqTIWZ0mSKmNxliSpMhZnSZIqY3GWJKkyFmdJkipj\ncZYkqTIWZ0mSKjPay0wRsQZYCkwCp2fmjS2fnQa8BtgB3JSZb4mIhwGXAo9rpp+SmbfPc+ySJA2l\nGa+cI2IFsDgzlwGnAue2fLYQeDuwPDOPAQ6PiKXAycB/NNPeB5zdj+AlSRpGvQxrnwCsBcjMW4BF\nTVEGuLf5eUREjAL7AT9p2ny6medLwNHzGbQkScOsl2HtA4ENLe8nmmlbM/M/I+Is4Hbg58DHMvPW\niDiwmY/M3BkRkxGxd2be22klixbtx+jogj3+IrUZHx8bdAhDybz2h3ntD/PaHw+FvPZ0z7nNyNSL\n5gr6z4DfBLYCX46Ip3Vr08mWLffsQSh1Gh8fY2Ji26DDGDrmtT/Ma3+Y1/4Yprx2O8noZVh7E+VK\necrBwObm9WHA7Zl5V3NVfD1wZGub5uGwkW5XzZIkaZdeivM6YCVARCwBNmXm1GnLRuCwiHh48/7p\nwHeaNi9rpp0EXDNfAUuSNOxmHNbOzPURsSEi1gM7gdMiYhVwd2Z+OiI+CFwTEduB9Zl5fUQsAH4n\nIm4AfgGs6t9XkCRpuIxMTk4OOgYAJia21RHIPBimeyI1Ma/9YV77w7z2xzDldXx8rOPzWP6FMEmS\nKmNxliSpMhZnSZIqY3GWJKkyFmdJkipjcZYkqTIWZ0mSKmNxliSpMhZnSZIqY3GWJKkyFmdJkipj\ncZYkqTIWZ0mSKmNxliSpMhZnSZIqY3GWJKkyFmdJkipjcZYkqTIWZ0mSKmNxliSpMhZnSZIqY3GW\nJKkyFmdJkioz2stMEbEGWApMAqdn5o0tnz0G+CiwN3BzZr5xpjaSJKmzGa+cI2IFsDgzlwGnAue2\nzbIaWJ2ZRwE7IuKxPbSRJEkd9DKsfQKwFiAzbwEWRcRCgIjYC1gOfLb5/LTM/H63NpIkqbteivOB\nwETL+4lmGsA4sA1YExE3RMTZPbSRJEld9HTPuc1I2+tDgHOAjcA/RsTzZ2gzrUWL9mN0dMEehFOn\n8fGxQYcwlMxrf5jX/jCv/fFQyGsvxXkTu1/1Hgxsbl7fBXwvM28DiIirgSfP0GZaW7bc02PI9Rsf\nH2NiYtugwxg65rU/zGt/mNf+GKa8djvJ6GVYex2wEiAilgCbMnMbQGZuB26PiMXNvEcC2a2NJEnq\nbsYr58xcHxEbImI9sBM4LSJWAXdn5qeBtwCXNg+H/Qvwuczc2d6mf19BkqThMjI5OTnoGACYmNhW\nRyDzYJiGXWpiXvvDvPaHee2PYcrr+PhYx+ex/AthkiRVxuIsSVJlLM6SJFXG4ixJUmUszpIkVcbi\nLElSZSzOkiRVxuIsSVJlLM6SJFXG4ixJUmUszpIkVcbiLElSZSzOkiRVxuIsSVJlLM6SJFXG4ixJ\nUmUszpIkVcbiLElSZSzOkiRVxuIsSVJlLM6SJFXG4ixJUmUszpIkVcbiLElSZUZ7mSki1gBLgUng\n9My8cZp5zgaWZeaxvbaRJEkPNOOVc0SsABZn5jLgVODcaeY5HHjWbNpIkqTp9TKsfQKwFiAzbwEW\nRcTCtnlWA++cZRtJkjSNXorzgcBEy/uJZhoAEbEKuA7Y2GsbSZLUWU/3nNuMTL2IiP2BU4BnA4f0\n0qaTRYv2Y3R0wR6EU6fx8bFBhzCUzGt/mNf+MK/98VDIay/FeRO7X/UeDGxuXh8PjAPXA/sAT2we\nBOvWZlpbttzTY8j1Gx8fY2Ji26DDGDrmtT/Ma3+Y1/4Yprx2O8noZVh7HbASICKWAJsycxtAZl6e\nmYdn5lLgxcDNmfkn3dpIkqTuZizOmbke2BAR6ylPXZ8WEasi4sWzaTNfAUuSNOxGJicnBx0DABMT\n2+oIZB4M07BLTcxrf5jX/jCv/TFMeR0fH+v4PJZ/IUySpMpYnCVJqozFWZKkylicJUmqjMVZkqTK\nWJwlSaqMxVmSpMpYnCVJqozFWZKkylicJUmqjMVZkqTKWJwlSaqMxVmSpMpYnCVJqozFWZKkylic\nJUmqjMVZkqTKWJwlSaqMxVmSpMpYnCVJqozFWZKkylicJUmqjMVZkqTKWJwlSarMaC8zRcQaYCkw\nCZyemTe2fHYccDawA0jgDZm5s1sbSZLU2YxXzhGxAlicmcuAU4Fz22a5EFiZmUcDY8Bze2gjSZI6\n6GVY+wRgLUBm3gIsioiFLZ8fmZl3NK8ngEf10EaSJHXQy7D2gcCGlvcTzbStAJm5FSAiDgJOBN5F\nGebu2GY6ixbtx+jogtnEXrXx8bFBhzCUzGt/mNf+MK/98VDIa0/3nNuMtE+IiEcDnwP+MDN/HBEz\ntmm3Zcs9exBKncbHx5iY2DboMIaOee0P89of5rU/himv3U4yeinOmyhXvVMOBjZPvWmGq78AvDMz\n1/XSRpIkddbLPed1wEqAiFgCbMrM1tOW1cCazPziLNpIkqQOZrxyzsz1EbEhItYDO4HTImIVcDdw\nJfBaYHFEvKFp8g+ZeWF7m/6EL0nS8OnpnnNmntE26f+1vN6nxzaSJKkH/oUwSZIqY3GWJKkyFmdJ\nkipjcZYkqTIWZ0mSKmNxliSpMhZnSZIqY3GWJKkyFmdJkipjcZYkqTIWZ0mSKmNxliSpMhZnSZIq\n09P/SvXL4vX/48uDDqE6l5xx/KBDkCTNklfOkiRVZqiunNUfjkg8kCMSkvrJK2dJkipjcZYkqTIO\na0sD4u2C3XmrQNrFK2dJkirjlbOkoeKIxO4ckfjlZHGWJHXlCc8D9fukx2FtSZIqY3GWJKkyFmdJ\nkipjcZYkqTIWZ0mSKjMyOTk56BgkSVILr5wlSaqMxVmSpMpYnCVJqozFWZKkylicJUmqjMVZkqTK\nWJwfBBHxiIjY2Dbt0Ii4qXn9sYh4eERcGhEvGESM/RYRqyLixQOO4aV70GbgcXfSxPY/H6R1HRsR\nlzevP/NgrHNQImJhRJzY53Ws7Ofyp1nfjPt+RDw3It70YMSjmfm/UlUgM18JEBGDDqVvMvPSQa4/\nIg4FXgV8cjbtBh13jTLzRYOOoc+WACcC6/q4jjOAy/u4/Pv1uu9n5hcfjHjUG4szEBGPBf4PsIOS\nk9cAVwJPBkaALcBxmXlTRFwJ/D7wu8Arm0WszcwPRMSlwL3Ao4BTKAfDvsANM6x/I/CUlvdfB07O\nzNsi4teBz2TmkfPyZWchIlYBK4ADKLl4J+UgPxx4dWZ+PSJOA04GdlLysDoiLga+kJmXR8RFwJeA\nJwF3Zeb5EXEO8F+A7cAbgW8Dfwv8OvArwJmZ+fmIuBa4Cji+ieGkzPx+S3xnNm0eCxwEvD0zvxgR\nLwHe1iz/psx8G3ABcFREvJsyYjQVy1OA8zPz2Ij4LrAWOBr4D+D5wLuBu4APTxfjfOV6Dh4fEVcA\njwHWAO8ArgDupMR7CbA3ZfucCkwClwG3Ac8E/gZ4KmV7XJCZF0TEcuD9wH3AD4Dfa11hRNyVmQdE\nxLOB91L2+S3AyzPz3v5+3QeKiEdSCt3DKd/99zLz8RHxHXbl4iPAxZRc7ADekJnfj4i3ASsp+8QV\nmXkWZV9ZGBG3ZuaFLeu5DfjfzfzfBTYALwO+k5mvjoinNW3vo+T7ZcA2St9yELAP8BfAbwFPi4hP\nZeZLIuJ9wHJgAWVf/GhbX/Jk5tYX7Uuz72fme7rkcRWlH9oLOKpp9+HMvKhZ3k8px/EBwCmZ+c2I\n+KsO824CjqQcm6/OzJs79BVHAB8CftH8vKLZPh8BFlH64zdn5j+3xTrX9Z7ZfI/fAJ4A/DnweuBQ\n4HmZeXtE/CWlLxhttstlnfqk6bZhpzz3ymHtYiVwVWYeB5xOOZA2UHbUI4CbgGURsRfwa5S8raJs\njOXAKyLiic2yfpKZL6UU+G9l5nLg/84ynssoOynAC4E5b+g5WNzEcDal439x8/pVEfF4Su6OAZ4F\nvLQ50flvwNsj4ijgkMz82NTCmg79MZm5FPgzyvfcH1iXmSuAlwNntax/a2aeAHwBeMk08R2SmSdS\nDr6zI+IRlAPt+GZ5j4mIo4EPAtd165woB+nfZeYySsfw1JbPusU4SL8JvAg4FngPpfh8ITPf17y/\nODOPpXSAZzZtfpty8vJ84AOUfJ3EriJ8LvCizDwe+BGlyExnEeUkcgWwFXjOPH6v2Xgt8K+ZeQzl\npGqkmf4wduXivcDqZl/6a+BdLe2PAZYCqyJiIWVf+XhrYW4sAG4GnkHptDdm5lHA8oj4VeDRlEJy\nHPBPwKsphfiAzHwWJT/7Z+YHgbubwrwceFzz+fHAn0fEw5v1TfUlc+2Letn3W21scrmcsg9NGc3M\nZze5e3dE7Ntl3n0y8znAOcBru/QVpwAfavbRDwAHAm8BvthsqzcBq1uDm6f1QtkWzwU+Abyu5fUL\nI+JZwFMy82jKdjkzIsaadrv1STNswz1mcS7WUTbkasrG/RpwHeWAPRo4j3Jl8VuUg/MI4GuZuT0z\nt1MOxKc1y/pG8/twYH3z+tpZxvNRdhWiFzDY4nxTZk4Cm4F/zswdlA77kZQz18XANc3PGHBoZv4Y\nuBD4HPDmtuUtoeSLzPxKZr6LcjXwjIj4J8rV3qNa5r+++X1Hs852VzfL+hfgEMoVxmOBK5uz3MXA\n43r8rltbztDb19ctxkG6ITPva3K+lRLX1D74dHbte9dQ9luA25r5NwN3ZuYPabZpRPwaJWefavJ3\nHCWv05kALoqI65r5BpWTw2j2KeCzbZ9N5eKZlA72WspJ5lSs91CO9WsoV0L7z7CubzTHw4+AbzbT\n7qTsKz8C3t/k41XNOr4NjEXEZZSO+2Nty3smsLSJ60pKn3xQW+xz7Ytma/+IWE8pPuMt07/U/P4q\nEJn5n13mbT9up+0rgM8A74qI91L2xW9TcvLGJicfou24n6f1wq78bGbXtpzq255OyTuZ+TPgX5vl\nTLeObttwjzmsDWTmt5ohqRMpV1+XUDq1d1CGyi6mnOEdTdnAk+w6O4ddw4ZQhpJoPp+aNquToMz8\ncUTcERHPAPZqOs9B2d7h9Qjlu/5jZv7BNO0OpAyDPZoyBDhlBw/Mx8mUTnF58/umLuts176se4EN\nzdnz/SLi2Ja3rX9Q/mEd1tW+vm4xDlL7H8efZNc+2Lqftu6jM23THzZXMvdry9+US4DnZ+YtEXH+\nrCOfP63HWns+7m35/bLM3Dz1QUQ8DngrcERm/jQivtXDurrl7hzgA82tlT8FHpGZ90TEUkoHvopy\nsv36tvguzsyzW1fSPH8yFfu1zK0vmo0jKSMEKzLzvoj4actnU8faCDAZESsoJxzTzdtzX9H0cy8A\n/rbJ272UEYivThfgfKw3Io6n+7bsltfp1vGAbThXXjkDEfFKyhDGWsoQ39Mz81bKfbxHZuY24N8p\n93auoZxlLYuI0YgYpZzJfrNtsUk5+4JyVTFbl1HuXz0oD43soQ3AcRGxX0SMRMQ5UZ46fzzlROcE\nYE2Toyk30uQjIo6IiAsoVyz/lpk7KSMGe88ihmOaZT0V+B4l74dFxKOb6WdFxCGUA2sqjq3sOrM9\npsf1zCXGfloWEQsiYpxyL/wnLZ/dn2vKswMznlBk5haAiDi8+f3mJrfTeSTw/WZI9zgGl5Pb2HWs\n/dcO83ydcvwSEcdHxMmUbXpnU5iXUEZYpjrhPblwOQC4LSL2AZ4H7N0s9+TMvIEyRHt4M+9U3/t1\n4KSI2Csi9o2I89oXOg990Wy+z6HAD5qi90JgQURMbdflze9llCvJA7rM265TX/FHlOHlv6c8M3EE\nu2+rwyPirW3LmvN6e8jDjZRbRTS3yp4IfKfDvDNuwz1hcS5uBc6PiC9THtj4m2b6nZQOH8oGODQz\n78jMjZRh2+soQxwXZeb3dl8kf0cZ6rgaCB54Rj+Tz1EeVqi2OGd5OOuvga8AXwP+PTN/Thl6e0eT\npyuBP2lp8xXgloi4nnJv88OUB+dOanL1M+COKA9u9WJrRHwW+HvgjMy8h3LP6opmCPpRlIdEbgGW\nRMQa4FPAiyLiKuBXe1zPXGLsp29T7pNdTXlgr3U/ezflds2XKVdtf9HjMk8FPtJso2MoJzzTuYAy\njHoh8JfAOyJizsN5e+BSyn3fayn3YXdMM8+ZwO9GxFcoefgq5VmQnzb7ySuA/0UZRr2Zcu/2T2cZ\nx3mUBwo/0bx+HWUY9TVNLq+i3P8F+GZEfCMz11OK7Fcpx9GGDsueS1/Uuu/PZC2wuBmafyLweXb1\nh/tGxOcp9+/fQxnm7jTvbrr0Fd8FPtEcVydTjuPzgN9ocnZR06bVfKy3q+ZkakOzv1xF6Vt+1mHe\nXrfhrPhfRlYqIo4DVmXm6wYdS62iPHF5V2YOckhVA9YMTz8pM6+MiGXAWc1DgpqFiPh94AmZecY0\nn10KXJ51/AuFhwTvOVcoIs6iPNk56z+aIT0E3Q28tRnJGAH+eMDx/NJpTmr+OzDd8yMaAK+cJUmq\njPecJUmqjMVZkqTKWJwlSaqMxVmSpMpYnCVJqozFWZKkyvx/IweF+srHXAIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9955addb70>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FkbY9Fm8io9d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}